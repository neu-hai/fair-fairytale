{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec2a555",
   "metadata": {},
   "source": [
    "# Create Test Data for brave-tin-soldier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f596a624",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>start_id</th>\n",
       "      <th>end_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>They were given him for a birthday present , and he stood at the table to set them up .</td>\n",
       "      <td>99</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The soldiers were all exactly alike , excepting one , who had only one leg ; he had been left to the last , and then there was not enough of the melted tin to finish him , so they made him to stand firmly on one leg , and this caused him to be very remarkable . '</td>\n",
       "      <td>119</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2,\"The table on which the tin soldiers stood , was covered with other playthings , but the most attractive to the eye was a pretty little paper castle .</td>\n",
       "      <td>178</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Through the small windows the rooms could be seen .</td>\n",
       "      <td>207</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In front of the castle a number of little trees surrounded a piece of looking - glass , which was intended to represent a transparent lake .</td>\n",
       "      <td>217</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Swans , made of wax , swam on the lake , and were reflected in it .</td>\n",
       "      <td>244</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>All this was very pretty , but the prettiest of all was a tiny little lady , who stood at the open door of the castle ; she , also , was made of paper , and she wore a dress of clear muslin , with a narrow blue ribbon over her shoulders just like a scarf .</td>\n",
       "      <td>261</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>In front of these was fixed a glittering tinsel rose , as large as her whole face . '</td>\n",
       "      <td>319</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3,\"The little lady was a dancer , and she stretched out both her arms , and raised one of her legs so high , that the tin soldier could not see it at all , and he thought that she , like himself , had only one leg . ' '</td>\n",
       "      <td>338</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                   sentence  \\\n",
       "5                                                                                                                                                                                   They were given him for a birthday present , and he stood at the table to set them up .   \n",
       "6   The soldiers were all exactly alike , excepting one , who had only one leg ; he had been left to the last , and then there was not enough of the melted tin to finish him , so they made him to stand firmly on one leg , and this caused him to be very remarkable . '   \n",
       "7                                                                                                                  2,\"The table on which the tin soldiers stood , was covered with other playthings , but the most attractive to the eye was a pretty little paper castle .   \n",
       "8                                                                                                                                                                                                                       Through the small windows the rooms could be seen .   \n",
       "9                                                                                                                              In front of the castle a number of little trees surrounded a piece of looking - glass , which was intended to represent a transparent lake .   \n",
       "10                                                                                                                                                                                                      Swans , made of wax , swam on the lake , and were reflected in it .   \n",
       "11         All this was very pretty , but the prettiest of all was a tiny little lady , who stood at the open door of the castle ; she , also , was made of paper , and she wore a dress of clear muslin , with a narrow blue ribbon over her shoulders just like a scarf .   \n",
       "12                                                                                                                                                                                    In front of these was fixed a glittering tinsel rose , as large as her whole face . '   \n",
       "13                                              3,\"The little lady was a dancer , and she stretched out both her arms , and raised one of her legs so high , that the tin soldier could not see it at all , and he thought that she , like himself , had only one leg . ' '   \n",
       "\n",
       "    start_id  end_id  \n",
       "5         99     118  \n",
       "6        119     177  \n",
       "7        178     206  \n",
       "8        207     216  \n",
       "9        217     243  \n",
       "10       244     260  \n",
       "11       261     318  \n",
       "12       319     337  \n",
       "13       338     388  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = \"/home/gxu21/ECONET/code/data_process/FairytaleQA_Dataset/split_by_origin/andersen-fairybook/brave-tin-soldier-story/brave-tin-soldier-story.tokens\"\n",
    "df = pd.read_csv(path, sep=\"\t\")\n",
    "#words is a list of all extracted tokens from the .token file\n",
    "words = list(df[\"word\"])\n",
    "len(words)\n",
    "words_dict = dict()\n",
    "for i,w in enumerate(words):\n",
    "    words_dict[i] = w\n",
    "\n",
    "#split the words into a new df of sentences, which includes their start and end token_pos\n",
    "sentences = []\n",
    "start = []\n",
    "end = []\n",
    "sent = None\n",
    "for i,w in enumerate(words):\n",
    "    if sent == None:\n",
    "        if w == \"\\t\":\n",
    "            sent+= \"'\"\n",
    "        else:\n",
    "            sent = w\n",
    "        start_id =i\n",
    "    else:\n",
    "        if w == \"\\t\":\n",
    "            sent+= \" '\"\n",
    "        else:\n",
    "            sent+= \" \"+ w\n",
    "    if (w == \".\" or w == \"\\t\") and (i+1>=len(words) or words[i+1]!='\\t'):\n",
    "        end_id = i\n",
    "        sentences.append(sent)\n",
    "        start.append(start_id)\n",
    "        end.append(end_id)\n",
    "        sent = None\n",
    "sent_df = pd.DataFrame({\"sentence\":sentences})\n",
    "sent_df[\"start_id\"] = start\n",
    "sent_df[\"end_id\"] = end\n",
    "pd.set_option('display.max_colwidth', None)  # or 199\n",
    "sent_df= sent_df.iloc[5:14]\n",
    "sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2962bf93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigger</th>\n",
       "      <th>v_s</th>\n",
       "      <th>v_e</th>\n",
       "      <th>arg0</th>\n",
       "      <th>a0_s</th>\n",
       "      <th>a0_e</th>\n",
       "      <th>arg1</th>\n",
       "      <th>a1_s</th>\n",
       "      <th>a1_e</th>\n",
       "      <th>arg2</th>\n",
       "      <th>a2_s</th>\n",
       "      <th>a2_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>were</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>were</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exactly alike</td>\n",
       "      <td>123.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stood</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the tin soldiers</td>\n",
       "      <td>182.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>could</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>surrounded</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>a number of little trees</td>\n",
       "      <td>222.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>a piece of looking - glass , which was intended to represent a transparent lake</td>\n",
       "      <td>228.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>made</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>of wax</td>\n",
       "      <td>247.0</td>\n",
       "      <td>248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>was</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>very pretty</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>was</td>\n",
       "      <td>323</td>\n",
       "      <td>323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>was</td>\n",
       "      <td>341</td>\n",
       "      <td>341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>a dancer</td>\n",
       "      <td>342.0</td>\n",
       "      <td>343.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       trigger  v_s  v_e                      arg0   a0_s   a0_e  \\\n",
       "4         were  100  100                       NaN    NaN    NaN   \n",
       "5         were  121  121                       NaN    NaN    NaN   \n",
       "6        stood  185  185                       NaN    NaN    NaN   \n",
       "7        could  213  213                       NaN    NaN    NaN   \n",
       "8   surrounded  227  227  a number of little trees  222.0  226.0   \n",
       "9         made  246  246                       NaN    NaN    NaN   \n",
       "10         was  263  263                       NaN    NaN    NaN   \n",
       "11         was  323  323                       NaN    NaN    NaN   \n",
       "12         was  341  341                       NaN    NaN    NaN   \n",
       "\n",
       "                                                                               arg1  \\\n",
       "4                                                                               NaN   \n",
       "5                                                                               NaN   \n",
       "6                                                                  the tin soldiers   \n",
       "7                                                                               NaN   \n",
       "8   a piece of looking - glass , which was intended to represent a transparent lake   \n",
       "9                                                                               NaN   \n",
       "10                                                                              NaN   \n",
       "11                                                                              NaN   \n",
       "12                                                                              NaN   \n",
       "\n",
       "     a1_s   a1_e           arg2   a2_s   a2_e  \n",
       "4     NaN    NaN            NaN    NaN    NaN  \n",
       "5     0.0    1.0  exactly alike  123.0  124.0  \n",
       "6   182.0  184.0            NaN    0.0    1.0  \n",
       "7     NaN    NaN            NaN    NaN    NaN  \n",
       "8   228.0  242.0            NaN    NaN    NaN  \n",
       "9     0.0    0.0         of wax  247.0  248.0  \n",
       "10    0.0    1.0    very pretty  264.0  265.0  \n",
       "11    NaN    NaN            NaN    NaN    NaN  \n",
       "12    NaN    2.0       a dancer  342.0  343.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('allen_srl_event.csv')\n",
    "df = df.iloc[4:13]\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4d4a37e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They were given him for a birthday present , and he stood at the table to set them up .The soldiers were all exactly alike , excepting one , who had only one leg ; he had been left to the last , and then there was not enough of the melted tin to finish him , so they made him to stand firmly on one leg , and this caused him to be very remarkable . '\n",
      "1 21\n",
      "were were\n",
      "The soldiers were all exactly alike , excepting one , who had only one leg ; he had been left to the last , and then there was not enough of the melted tin to finish him , so they made him to stand firmly on one leg , and this caused him to be very remarkable . '2,\"The table on which the tin soldiers stood , was covered with other playthings , but the most attractive to the eye was a pretty little paper castle .\n",
      "2 66\n",
      "were stood\n",
      "2,\"The table on which the tin soldiers stood , was covered with other playthings , but the most attractive to the eye was a pretty little paper castle .Through the small windows the rooms could be seen .\n",
      "7 34\n",
      "stood could\n",
      "Through the small windows the rooms could be seen .In front of the castle a number of little trees surrounded a piece of looking - glass , which was intended to represent a transparent lake .\n",
      "6 19\n",
      "could surrounded\n",
      "In front of the castle a number of little trees surrounded a piece of looking - glass , which was intended to represent a transparent lake .Swans , made of wax , swam on the lake , and were reflected in it .\n",
      "10 28\n",
      "surrounded made\n",
      "Swans , made of wax , swam on the lake , and were reflected in it .All this was very pretty , but the prettiest of all was a tiny little lady , who stood at the open door of the castle ; she , also , was made of paper , and she wore a dress of clear muslin , with a narrow blue ribbon over her shoulders just like a scarf .\n",
      "2 18\n",
      "made was\n",
      "All this was very pretty , but the prettiest of all was a tiny little lady , who stood at the open door of the castle ; she , also , was made of paper , and she wore a dress of clear muslin , with a narrow blue ribbon over her shoulders just like a scarf .In front of these was fixed a glittering tinsel rose , as large as her whole face . '\n",
      "2 11\n",
      "was was\n",
      "In front of these was fixed a glittering tinsel rose , as large as her whole face . '3,\"The little lady was a dancer , and she stretched out both her arms , and raised one of her legs so high , that the tin soldier could not see it at all , and he thought that she , like himself , had only one leg . ' '\n",
      "4 22\n",
      "was was\n"
     ]
    }
   ],
   "source": [
    "#curate two_sentences pair, + the token position of the verb\n",
    "sent_ls = []\n",
    "event_ids = []\n",
    "verbs = []\n",
    "\n",
    "for i in range(1, df.shape[0]):\n",
    "    concat = sent_df.iloc[i-1][\"sentence\"] + sent_df.iloc[i][\"sentence\"]\n",
    "#     offset = int(sent_df.iloc[i-1][\"start_id\"])\n",
    "#     l_event, r_event = int(df.iloc[i-1][\"v_s\"]) - offset, int(df.iloc[i][\"v_s\"]) - offset\n",
    "    events = get_predicate(concat)\n",
    "    tokens = events[0][-1]\n",
    "    lverb, rverb = df.iloc[i-1][\"trigger\"], df.iloc[i][\"trigger\"]\n",
    "    l_event = tokens.index(lverb)\n",
    "    r_event = l_event + tokens[l_event+1:].index(rverb)+1\n",
    "    \n",
    "    sent_ls.append(concat)\n",
    "    event_ids.append([l_event, r_event])\n",
    "    verbs.append([lverb, rverb])\n",
    "    print(concat)\n",
    "    print(l_event, r_event)\n",
    "    print(lverb,rverb)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0310cc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print the triggers: ---------  \n",
      "\n",
      "were he\n",
      "print the triggers: ---------  \n",
      "\n",
      "soldiers who\n",
      "print the triggers: ---------  \n",
      "\n",
      "table covered\n",
      "print the triggers: ---------  \n",
      "\n",
      "the front\n",
      "print the triggers: ---------  \n",
      "\n",
      "front surrounded\n",
      "print the triggers: ---------  \n",
      "\n",
      ", ,\n",
      "print the triggers: ---------  \n",
      "\n",
      "this all\n",
      "print the triggers: ---------  \n",
      "\n",
      "front ,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'L_0': {'rel_type': 'BEFORE',\n",
       "  'rev': None,\n",
       "  'doc_dictionary': OrderedDict([('[0:4)', ('They', None)),\n",
       "               ('[5:9)', ('were', None)),\n",
       "               ('[10:15)', ('given', None)),\n",
       "               ('[16:19)', ('him', None)),\n",
       "               ('[20:23)', ('for', None)),\n",
       "               ('[24:25)', ('a', None)),\n",
       "               ('[26:34)', ('birthday', None)),\n",
       "               ('[35:42)', ('present', None)),\n",
       "               ('[43:44)', (',', None)),\n",
       "               ('[45:48)', ('and', None)),\n",
       "               ('[49:51)', ('he', None)),\n",
       "               ('[52:57)', ('stood', None)),\n",
       "               ('[58:60)', ('at', None)),\n",
       "               ('[61:64)', ('the', None)),\n",
       "               ('[65:70)', ('table', None)),\n",
       "               ('[71:73)', ('to', None)),\n",
       "               ('[74:77)', ('set', None)),\n",
       "               ('[78:82)', ('them', None)),\n",
       "               ('[83:85)', ('up', None)),\n",
       "               ('[86:90)', ('.The', None)),\n",
       "               ('[91:99)', ('soldiers', None)),\n",
       "               ('[100:104)', ('were', None)),\n",
       "               ('[105:108)', ('all', None)),\n",
       "               ('[109:116)', ('exactly', None)),\n",
       "               ('[117:122)', ('alike', None)),\n",
       "               ('[123:124)', (',', None)),\n",
       "               ('[125:134)', ('excepting', None)),\n",
       "               ('[135:138)', ('one', None)),\n",
       "               ('[139:140)', (',', None)),\n",
       "               ('[141:144)', ('who', None)),\n",
       "               ('[145:148)', ('had', None)),\n",
       "               ('[149:153)', ('only', None)),\n",
       "               ('[154:157)', ('one', None)),\n",
       "               ('[158:161)', ('leg', None)),\n",
       "               ('[162:163)', (';', None)),\n",
       "               ('[164:166)', ('he', None)),\n",
       "               ('[167:170)', ('had', None)),\n",
       "               ('[171:175)', ('been', None)),\n",
       "               ('[176:180)', ('left', None)),\n",
       "               ('[181:183)', ('to', None)),\n",
       "               ('[184:187)', ('the', None)),\n",
       "               ('[188:192)', ('last', None)),\n",
       "               ('[193:194)', (',', None)),\n",
       "               ('[195:198)', ('and', None)),\n",
       "               ('[199:203)', ('then', None)),\n",
       "               ('[204:209)', ('there', None)),\n",
       "               ('[210:213)', ('was', None)),\n",
       "               ('[214:217)', ('not', None)),\n",
       "               ('[218:224)', ('enough', None)),\n",
       "               ('[225:227)', ('of', None)),\n",
       "               ('[228:231)', ('the', None)),\n",
       "               ('[232:238)', ('melted', None)),\n",
       "               ('[239:242)', ('tin', None)),\n",
       "               ('[243:245)', ('to', None)),\n",
       "               ('[246:252)', ('finish', None)),\n",
       "               ('[253:256)', ('him', None)),\n",
       "               ('[257:258)', (',', None)),\n",
       "               ('[259:261)', ('so', None)),\n",
       "               ('[262:266)', ('they', None)),\n",
       "               ('[267:271)', ('made', None)),\n",
       "               ('[272:275)', ('him', None)),\n",
       "               ('[276:278)', ('to', None)),\n",
       "               ('[279:284)', ('stand', None)),\n",
       "               ('[285:291)', ('firmly', None)),\n",
       "               ('[292:294)', ('on', None)),\n",
       "               ('[295:298)', ('one', None)),\n",
       "               ('[299:302)', ('leg', None)),\n",
       "               ('[303:304)', (',', None)),\n",
       "               ('[305:308)', ('and', None)),\n",
       "               ('[309:313)', ('this', None)),\n",
       "               ('[314:320)', ('caused', None)),\n",
       "               ('[321:324)', ('him', None)),\n",
       "               ('[325:327)', ('to', None)),\n",
       "               ('[328:330)', ('be', None)),\n",
       "               ('[331:335)', ('very', None)),\n",
       "               ('[336:346)', ('remarkable', None)),\n",
       "               ('[347:348)', ('.', None)),\n",
       "               ('[349:350)', (\"'\", None))]),\n",
       "  'event_labels': None,\n",
       "  'doc_id': None,\n",
       "  'left_event': <utils.Event at 0x7f0b0814b880>,\n",
       "  'right_event': <utils.Event at 0x7f0b08118460>},\n",
       " 'L_1': {'rel_type': 'BEFORE',\n",
       "  'rev': None,\n",
       "  'doc_dictionary': OrderedDict([('[0:3)', ('The', None)),\n",
       "               ('[4:12)', ('soldiers', None)),\n",
       "               ('[13:17)', ('were', None)),\n",
       "               ('[18:21)', ('all', None)),\n",
       "               ('[22:29)', ('exactly', None)),\n",
       "               ('[30:35)', ('alike', None)),\n",
       "               ('[36:37)', (',', None)),\n",
       "               ('[38:47)', ('excepting', None)),\n",
       "               ('[48:51)', ('one', None)),\n",
       "               ('[52:53)', (',', None)),\n",
       "               ('[54:57)', ('who', None)),\n",
       "               ('[58:61)', ('had', None)),\n",
       "               ('[62:66)', ('only', None)),\n",
       "               ('[67:70)', ('one', None)),\n",
       "               ('[71:74)', ('leg', None)),\n",
       "               ('[75:76)', (';', None)),\n",
       "               ('[77:79)', ('he', None)),\n",
       "               ('[80:83)', ('had', None)),\n",
       "               ('[84:88)', ('been', None)),\n",
       "               ('[89:93)', ('left', None)),\n",
       "               ('[94:96)', ('to', None)),\n",
       "               ('[97:100)', ('the', None)),\n",
       "               ('[101:105)', ('last', None)),\n",
       "               ('[106:107)', (',', None)),\n",
       "               ('[108:111)', ('and', None)),\n",
       "               ('[112:116)', ('then', None)),\n",
       "               ('[117:122)', ('there', None)),\n",
       "               ('[123:126)', ('was', None)),\n",
       "               ('[127:130)', ('not', None)),\n",
       "               ('[131:137)', ('enough', None)),\n",
       "               ('[138:140)', ('of', None)),\n",
       "               ('[141:144)', ('the', None)),\n",
       "               ('[145:151)', ('melted', None)),\n",
       "               ('[152:155)', ('tin', None)),\n",
       "               ('[156:158)', ('to', None)),\n",
       "               ('[159:165)', ('finish', None)),\n",
       "               ('[166:169)', ('him', None)),\n",
       "               ('[170:171)', (',', None)),\n",
       "               ('[172:174)', ('so', None)),\n",
       "               ('[175:179)', ('they', None)),\n",
       "               ('[180:184)', ('made', None)),\n",
       "               ('[185:188)', ('him', None)),\n",
       "               ('[189:191)', ('to', None)),\n",
       "               ('[192:197)', ('stand', None)),\n",
       "               ('[198:204)', ('firmly', None)),\n",
       "               ('[205:207)', ('on', None)),\n",
       "               ('[208:211)', ('one', None)),\n",
       "               ('[212:215)', ('leg', None)),\n",
       "               ('[216:217)', (',', None)),\n",
       "               ('[218:221)', ('and', None)),\n",
       "               ('[222:226)', ('this', None)),\n",
       "               ('[227:233)', ('caused', None)),\n",
       "               ('[234:237)', ('him', None)),\n",
       "               ('[238:240)', ('to', None)),\n",
       "               ('[241:243)', ('be', None)),\n",
       "               ('[244:248)', ('very', None)),\n",
       "               ('[249:259)', ('remarkable', None)),\n",
       "               ('[260:261)', ('.', None)),\n",
       "               ('[262:263)', (\"'\", None)),\n",
       "               ('[263:269)', ('2,\"The', None)),\n",
       "               ('[270:275)', ('table', None)),\n",
       "               ('[276:278)', ('on', None)),\n",
       "               ('[279:284)', ('which', None)),\n",
       "               ('[285:288)', ('the', None)),\n",
       "               ('[289:292)', ('tin', None)),\n",
       "               ('[293:301)', ('soldiers', None)),\n",
       "               ('[302:307)', ('stood', None)),\n",
       "               ('[308:309)', (',', None)),\n",
       "               ('[310:313)', ('was', None)),\n",
       "               ('[314:321)', ('covered', None)),\n",
       "               ('[322:326)', ('with', None)),\n",
       "               ('[327:332)', ('other', None)),\n",
       "               ('[333:343)', ('playthings', None)),\n",
       "               ('[344:345)', (',', None)),\n",
       "               ('[346:349)', ('but', None)),\n",
       "               ('[350:353)', ('the', None)),\n",
       "               ('[354:358)', ('most', None)),\n",
       "               ('[359:369)', ('attractive', None)),\n",
       "               ('[370:372)', ('to', None)),\n",
       "               ('[373:376)', ('the', None)),\n",
       "               ('[377:380)', ('eye', None)),\n",
       "               ('[381:384)', ('was', None)),\n",
       "               ('[382:383)', ('a', None)),\n",
       "               ('[387:393)', ('pretty', None)),\n",
       "               ('[394:400)', ('little', None)),\n",
       "               ('[401:406)', ('paper', None)),\n",
       "               ('[407:413)', ('castle', None)),\n",
       "               ('[414:415)', ('.', None))]),\n",
       "  'event_labels': None,\n",
       "  'doc_id': None,\n",
       "  'left_event': <utils.Event at 0x7f0b080f41c0>,\n",
       "  'right_event': <utils.Event at 0x7f0b08155d00>},\n",
       " 'L_2': {'rel_type': 'BEFORE',\n",
       "  'rev': None,\n",
       "  'doc_dictionary': OrderedDict([('[0:6)', ('2,\"The', None)),\n",
       "               ('[7:12)', ('table', None)),\n",
       "               ('[13:15)', ('on', None)),\n",
       "               ('[16:21)', ('which', None)),\n",
       "               ('[22:25)', ('the', None)),\n",
       "               ('[26:29)', ('tin', None)),\n",
       "               ('[30:38)', ('soldiers', None)),\n",
       "               ('[39:44)', ('stood', None)),\n",
       "               ('[45:46)', (',', None)),\n",
       "               ('[47:50)', ('was', None)),\n",
       "               ('[51:58)', ('covered', None)),\n",
       "               ('[59:63)', ('with', None)),\n",
       "               ('[64:69)', ('other', None)),\n",
       "               ('[70:80)', ('playthings', None)),\n",
       "               ('[81:82)', (',', None)),\n",
       "               ('[83:86)', ('but', None)),\n",
       "               ('[87:90)', ('the', None)),\n",
       "               ('[91:95)', ('most', None)),\n",
       "               ('[96:106)', ('attractive', None)),\n",
       "               ('[107:109)', ('to', None)),\n",
       "               ('[110:113)', ('the', None)),\n",
       "               ('[114:117)', ('eye', None)),\n",
       "               ('[118:121)', ('was', None)),\n",
       "               ('[119:120)', ('a', None)),\n",
       "               ('[124:130)', ('pretty', None)),\n",
       "               ('[131:137)', ('little', None)),\n",
       "               ('[138:143)', ('paper', None)),\n",
       "               ('[144:150)', ('castle', None)),\n",
       "               ('[151:159)', ('.Through', None)),\n",
       "               ('[160:163)', ('the', None)),\n",
       "               ('[164:169)', ('small', None)),\n",
       "               ('[170:177)', ('windows', None)),\n",
       "               ('[178:181)', ('the', None)),\n",
       "               ('[182:187)', ('rooms', None)),\n",
       "               ('[188:193)', ('could', None)),\n",
       "               ('[194:196)', ('be', None)),\n",
       "               ('[197:201)', ('seen', None)),\n",
       "               ('[202:203)', ('.', None))]),\n",
       "  'event_labels': None,\n",
       "  'doc_id': None,\n",
       "  'left_event': <utils.Event at 0x7f0b08118fa0>,\n",
       "  'right_event': <utils.Event at 0x7f0d0ca44550>},\n",
       " 'L_3': {'rel_type': 'BEFORE',\n",
       "  'rev': None,\n",
       "  'doc_dictionary': OrderedDict([('[0:7)', ('Through', None)),\n",
       "               ('[8:11)', ('the', None)),\n",
       "               ('[12:17)', ('small', None)),\n",
       "               ('[18:25)', ('windows', None)),\n",
       "               ('[26:29)', ('the', None)),\n",
       "               ('[30:35)', ('rooms', None)),\n",
       "               ('[36:41)', ('could', None)),\n",
       "               ('[42:44)', ('be', None)),\n",
       "               ('[45:49)', ('seen', None)),\n",
       "               ('[50:53)', ('.In', None)),\n",
       "               ('[54:59)', ('front', None)),\n",
       "               ('[60:62)', ('of', None)),\n",
       "               ('[63:66)', ('the', None)),\n",
       "               ('[67:73)', ('castle', None)),\n",
       "               ('[68:69)', ('a', None)),\n",
       "               ('[76:82)', ('number', None)),\n",
       "               ('[83:85)', ('of', None)),\n",
       "               ('[86:92)', ('little', None)),\n",
       "               ('[93:98)', ('trees', None)),\n",
       "               ('[99:109)', ('surrounded', None)),\n",
       "               ('[110:111)', ('a', None)),\n",
       "               ('[112:117)', ('piece', None)),\n",
       "               ('[118:120)', ('of', None)),\n",
       "               ('[121:128)', ('looking', None)),\n",
       "               ('[129:130)', ('-', None)),\n",
       "               ('[131:136)', ('glass', None)),\n",
       "               ('[137:138)', (',', None)),\n",
       "               ('[139:144)', ('which', None)),\n",
       "               ('[145:148)', ('was', None)),\n",
       "               ('[149:157)', ('intended', None)),\n",
       "               ('[158:160)', ('to', None)),\n",
       "               ('[161:170)', ('represent', None)),\n",
       "               ('[171:172)', ('a', None)),\n",
       "               ('[173:184)', ('transparent', None)),\n",
       "               ('[185:189)', ('lake', None)),\n",
       "               ('[190:191)', ('.', None))]),\n",
       "  'event_labels': None,\n",
       "  'doc_id': None,\n",
       "  'left_event': <utils.Event at 0x7f0d0ca445e0>,\n",
       "  'right_event': <utils.Event at 0x7f0d0ca44b80>},\n",
       " 'L_4': {'rel_type': 'BEFORE',\n",
       "  'rev': None,\n",
       "  'doc_dictionary': OrderedDict([('[0:2)', ('In', None)),\n",
       "               ('[3:8)', ('front', None)),\n",
       "               ('[9:11)', ('of', None)),\n",
       "               ('[12:15)', ('the', None)),\n",
       "               ('[16:22)', ('castle', None)),\n",
       "               ('[17:18)', ('a', None)),\n",
       "               ('[25:31)', ('number', None)),\n",
       "               ('[32:34)', ('of', None)),\n",
       "               ('[35:41)', ('little', None)),\n",
       "               ('[42:47)', ('trees', None)),\n",
       "               ('[48:58)', ('surrounded', None)),\n",
       "               ('[59:60)', ('a', None)),\n",
       "               ('[61:66)', ('piece', None)),\n",
       "               ('[67:69)', ('of', None)),\n",
       "               ('[70:77)', ('looking', None)),\n",
       "               ('[78:79)', ('-', None)),\n",
       "               ('[80:85)', ('glass', None)),\n",
       "               ('[86:87)', (',', None)),\n",
       "               ('[88:93)', ('which', None)),\n",
       "               ('[94:97)', ('was', None)),\n",
       "               ('[98:106)', ('intended', None)),\n",
       "               ('[107:109)', ('to', None)),\n",
       "               ('[110:119)', ('represent', None)),\n",
       "               ('[120:121)', ('a', None)),\n",
       "               ('[122:133)', ('transparent', None)),\n",
       "               ('[134:138)', ('lake', None)),\n",
       "               ('[139:145)', ('.Swans', None)),\n",
       "               ('[146:147)', (',', None)),\n",
       "               ('[148:152)', ('made', None)),\n",
       "               ('[153:155)', ('of', None)),\n",
       "               ('[156:159)', ('wax', None)),\n",
       "               ('[160:161)', (',', None)),\n",
       "               ('[162:166)', ('swam', None)),\n",
       "               ('[167:169)', ('on', None)),\n",
       "               ('[170:173)', ('the', None)),\n",
       "               ('[174:178)', ('lake', None)),\n",
       "               ('[179:180)', (',', None)),\n",
       "               ('[181:184)', ('and', None)),\n",
       "               ('[185:189)', ('were', None)),\n",
       "               ('[190:199)', ('reflected', None)),\n",
       "               ('[200:202)', ('in', None)),\n",
       "               ('[203:205)', ('it', None)),\n",
       "               ('[206:207)', ('.', None))]),\n",
       "  'event_labels': None,\n",
       "  'doc_id': None,\n",
       "  'left_event': <utils.Event at 0x7f0b08155520>,\n",
       "  'right_event': <utils.Event at 0x7f0d0ca4d880>},\n",
       " 'L_5': {'rel_type': 'BEFORE',\n",
       "  'rev': None,\n",
       "  'doc_dictionary': OrderedDict([('[0:5)', ('Swans', None)),\n",
       "               ('[6:7)', (',', None)),\n",
       "               ('[8:12)', ('made', None)),\n",
       "               ('[13:15)', ('of', None)),\n",
       "               ('[16:19)', ('wax', None)),\n",
       "               ('[20:21)', (',', None)),\n",
       "               ('[22:26)', ('swam', None)),\n",
       "               ('[27:29)', ('on', None)),\n",
       "               ('[30:33)', ('the', None)),\n",
       "               ('[34:38)', ('lake', None)),\n",
       "               ('[39:40)', (',', None)),\n",
       "               ('[41:44)', ('and', None)),\n",
       "               ('[45:49)', ('were', None)),\n",
       "               ('[50:59)', ('reflected', None)),\n",
       "               ('[60:62)', ('in', None)),\n",
       "               ('[63:65)', ('it', None)),\n",
       "               ('[66:70)', ('.All', None)),\n",
       "               ('[71:75)', ('this', None)),\n",
       "               ('[76:79)', ('was', None)),\n",
       "               ('[80:84)', ('very', None)),\n",
       "               ('[85:91)', ('pretty', None)),\n",
       "               ('[92:93)', (',', None)),\n",
       "               ('[94:97)', ('but', None)),\n",
       "               ('[98:101)', ('the', None)),\n",
       "               ('[102:111)', ('prettiest', None)),\n",
       "               ('[112:114)', ('of', None)),\n",
       "               ('[115:118)', ('all', None)),\n",
       "               ('[119:122)', ('was', None)),\n",
       "               ('[120:121)', ('a', None)),\n",
       "               ('[125:129)', ('tiny', None)),\n",
       "               ('[130:136)', ('little', None)),\n",
       "               ('[137:141)', ('lady', None)),\n",
       "               ('[142:143)', (',', None)),\n",
       "               ('[144:147)', ('who', None)),\n",
       "               ('[148:153)', ('stood', None)),\n",
       "               ('[154:156)', ('at', None)),\n",
       "               ('[157:160)', ('the', None)),\n",
       "               ('[161:165)', ('open', None)),\n",
       "               ('[166:170)', ('door', None)),\n",
       "               ('[171:173)', ('of', None)),\n",
       "               ('[174:177)', ('the', None)),\n",
       "               ('[178:184)', ('castle', None)),\n",
       "               ('[185:186)', (';', None)),\n",
       "               ('[187:190)', ('she', None)),\n",
       "               ('[191:192)', (',', None)),\n",
       "               ('[193:197)', ('also', None)),\n",
       "               ('[198:199)', (',', None)),\n",
       "               ('[200:203)', ('was', None)),\n",
       "               ('[204:208)', ('made', None)),\n",
       "               ('[209:211)', ('of', None)),\n",
       "               ('[212:217)', ('paper', None)),\n",
       "               ('[218:219)', (',', None)),\n",
       "               ('[220:223)', ('and', None)),\n",
       "               ('[224:227)', ('she', None)),\n",
       "               ('[228:232)', ('wore', None)),\n",
       "               ('[233:234)', ('a', None)),\n",
       "               ('[235:240)', ('dress', None)),\n",
       "               ('[241:243)', ('of', None)),\n",
       "               ('[244:249)', ('clear', None)),\n",
       "               ('[250:256)', ('muslin', None)),\n",
       "               ('[257:258)', (',', None)),\n",
       "               ('[259:263)', ('with', None)),\n",
       "               ('[264:265)', ('a', None)),\n",
       "               ('[266:272)', ('narrow', None)),\n",
       "               ('[273:277)', ('blue', None)),\n",
       "               ('[278:284)', ('ribbon', None)),\n",
       "               ('[285:289)', ('over', None)),\n",
       "               ('[290:293)', ('her', None)),\n",
       "               ('[294:303)', ('shoulders', None)),\n",
       "               ('[304:308)', ('just', None)),\n",
       "               ('[309:313)', ('like', None)),\n",
       "               ('[314:315)', ('a', None)),\n",
       "               ('[316:321)', ('scarf', None)),\n",
       "               ('[322:323)', ('.', None))]),\n",
       "  'event_labels': None,\n",
       "  'doc_id': None,\n",
       "  'left_event': <utils.Event at 0x7f0d0ca44ee0>,\n",
       "  'right_event': <utils.Event at 0x7f0d0ca44c10>},\n",
       " 'L_6': {'rel_type': 'BEFORE',\n",
       "  'rev': None,\n",
       "  'doc_dictionary': OrderedDict([('[0:3)', ('All', None)),\n",
       "               ('[4:8)', ('this', None)),\n",
       "               ('[9:12)', ('was', None)),\n",
       "               ('[13:17)', ('very', None)),\n",
       "               ('[18:24)', ('pretty', None)),\n",
       "               ('[25:26)', (',', None)),\n",
       "               ('[27:30)', ('but', None)),\n",
       "               ('[31:34)', ('the', None)),\n",
       "               ('[35:44)', ('prettiest', None)),\n",
       "               ('[45:47)', ('of', None)),\n",
       "               ('[48:51)', ('all', None)),\n",
       "               ('[52:55)', ('was', None)),\n",
       "               ('[53:54)', ('a', None)),\n",
       "               ('[58:62)', ('tiny', None)),\n",
       "               ('[63:69)', ('little', None)),\n",
       "               ('[70:74)', ('lady', None)),\n",
       "               ('[75:76)', (',', None)),\n",
       "               ('[77:80)', ('who', None)),\n",
       "               ('[81:86)', ('stood', None)),\n",
       "               ('[87:89)', ('at', None)),\n",
       "               ('[90:93)', ('the', None)),\n",
       "               ('[94:98)', ('open', None)),\n",
       "               ('[99:103)', ('door', None)),\n",
       "               ('[104:106)', ('of', None)),\n",
       "               ('[107:110)', ('the', None)),\n",
       "               ('[111:117)', ('castle', None)),\n",
       "               ('[118:119)', (';', None)),\n",
       "               ('[120:123)', ('she', None)),\n",
       "               ('[124:125)', (',', None)),\n",
       "               ('[126:130)', ('also', None)),\n",
       "               ('[131:132)', (',', None)),\n",
       "               ('[133:136)', ('was', None)),\n",
       "               ('[137:141)', ('made', None)),\n",
       "               ('[142:144)', ('of', None)),\n",
       "               ('[145:150)', ('paper', None)),\n",
       "               ('[151:152)', (',', None)),\n",
       "               ('[153:156)', ('and', None)),\n",
       "               ('[157:160)', ('she', None)),\n",
       "               ('[161:165)', ('wore', None)),\n",
       "               ('[166:167)', ('a', None)),\n",
       "               ('[168:173)', ('dress', None)),\n",
       "               ('[174:176)', ('of', None)),\n",
       "               ('[177:182)', ('clear', None)),\n",
       "               ('[183:189)', ('muslin', None)),\n",
       "               ('[190:191)', (',', None)),\n",
       "               ('[192:196)', ('with', None)),\n",
       "               ('[197:198)', ('a', None)),\n",
       "               ('[199:205)', ('narrow', None)),\n",
       "               ('[206:210)', ('blue', None)),\n",
       "               ('[211:217)', ('ribbon', None)),\n",
       "               ('[218:222)', ('over', None)),\n",
       "               ('[223:226)', ('her', None)),\n",
       "               ('[227:236)', ('shoulders', None)),\n",
       "               ('[237:241)', ('just', None)),\n",
       "               ('[242:246)', ('like', None)),\n",
       "               ('[247:248)', ('a', None)),\n",
       "               ('[249:254)', ('scarf', None)),\n",
       "               ('[255:258)', ('.In', None)),\n",
       "               ('[259:264)', ('front', None)),\n",
       "               ('[265:267)', ('of', None)),\n",
       "               ('[268:273)', ('these', None)),\n",
       "               ('[274:277)', ('was', None)),\n",
       "               ('[278:283)', ('fixed', None)),\n",
       "               ('[284:285)', ('a', None)),\n",
       "               ('[286:296)', ('glittering', None)),\n",
       "               ('[297:303)', ('tinsel', None)),\n",
       "               ('[304:308)', ('rose', None)),\n",
       "               ('[309:310)', (',', None)),\n",
       "               ('[311:313)', ('as', None)),\n",
       "               ('[314:319)', ('large', None)),\n",
       "               ('[320:322)', ('as', None)),\n",
       "               ('[323:326)', ('her', None)),\n",
       "               ('[327:332)', ('whole', None)),\n",
       "               ('[333:337)', ('face', None)),\n",
       "               ('[338:339)', ('.', None)),\n",
       "               ('[340:341)', (\"'\", None))]),\n",
       "  'event_labels': None,\n",
       "  'doc_id': None,\n",
       "  'left_event': <utils.Event at 0x7f0b080b5370>,\n",
       "  'right_event': <utils.Event at 0x7f0b080b54c0>},\n",
       " 'L_7': {'rel_type': 'BEFORE',\n",
       "  'rev': None,\n",
       "  'doc_dictionary': OrderedDict([('[0:2)', ('In', None)),\n",
       "               ('[3:8)', ('front', None)),\n",
       "               ('[9:11)', ('of', None)),\n",
       "               ('[12:17)', ('these', None)),\n",
       "               ('[18:21)', ('was', None)),\n",
       "               ('[22:27)', ('fixed', None)),\n",
       "               ('[28:29)', ('a', None)),\n",
       "               ('[30:40)', ('glittering', None)),\n",
       "               ('[41:47)', ('tinsel', None)),\n",
       "               ('[48:52)', ('rose', None)),\n",
       "               ('[53:54)', (',', None)),\n",
       "               ('[55:57)', ('as', None)),\n",
       "               ('[58:63)', ('large', None)),\n",
       "               ('[64:66)', ('as', None)),\n",
       "               ('[67:70)', ('her', None)),\n",
       "               ('[71:76)', ('whole', None)),\n",
       "               ('[77:81)', ('face', None)),\n",
       "               ('[82:83)', ('.', None)),\n",
       "               ('[84:85)', (\"'\", None)),\n",
       "               ('[85:91)', ('3,\"The', None)),\n",
       "               ('[92:98)', ('little', None)),\n",
       "               ('[99:103)', ('lady', None)),\n",
       "               ('[104:107)', ('was', None)),\n",
       "               ('[105:106)', ('a', None)),\n",
       "               ('[110:116)', ('dancer', None)),\n",
       "               ('[117:118)', (',', None)),\n",
       "               ('[119:122)', ('and', None)),\n",
       "               ('[123:126)', ('she', None)),\n",
       "               ('[127:136)', ('stretched', None)),\n",
       "               ('[137:140)', ('out', None)),\n",
       "               ('[141:145)', ('both', None)),\n",
       "               ('[146:149)', ('her', None)),\n",
       "               ('[150:154)', ('arms', None)),\n",
       "               ('[155:156)', (',', None)),\n",
       "               ('[157:160)', ('and', None)),\n",
       "               ('[161:167)', ('raised', None)),\n",
       "               ('[168:171)', ('one', None)),\n",
       "               ('[172:174)', ('of', None)),\n",
       "               ('[175:178)', ('her', None)),\n",
       "               ('[179:183)', ('legs', None)),\n",
       "               ('[184:186)', ('so', None)),\n",
       "               ('[187:191)', ('high', None)),\n",
       "               ('[192:193)', (',', None)),\n",
       "               ('[194:198)', ('that', None)),\n",
       "               ('[199:202)', ('the', None)),\n",
       "               ('[203:206)', ('tin', None)),\n",
       "               ('[207:214)', ('soldier', None)),\n",
       "               ('[215:220)', ('could', None)),\n",
       "               ('[221:224)', ('not', None)),\n",
       "               ('[225:228)', ('see', None)),\n",
       "               ('[229:231)', ('it', None)),\n",
       "               ('[232:234)', ('at', None)),\n",
       "               ('[235:238)', ('all', None)),\n",
       "               ('[239:240)', (',', None)),\n",
       "               ('[241:244)', ('and', None)),\n",
       "               ('[245:247)', ('he', None)),\n",
       "               ('[248:255)', ('thought', None)),\n",
       "               ('[256:260)', ('that', None)),\n",
       "               ('[261:264)', ('she', None)),\n",
       "               ('[265:266)', (',', None)),\n",
       "               ('[267:271)', ('like', None)),\n",
       "               ('[272:279)', ('himself', None)),\n",
       "               ('[280:281)', (',', None)),\n",
       "               ('[282:285)', ('had', None)),\n",
       "               ('[286:290)', ('only', None)),\n",
       "               ('[291:294)', ('one', None)),\n",
       "               ('[295:298)', ('leg', None)),\n",
       "               ('[299:300)', ('.', None)),\n",
       "               ('[301:302)', (\"'\", None)),\n",
       "               ('[303:304)', (\"'\", None))]),\n",
       "  'event_labels': None,\n",
       "  'doc_id': None,\n",
       "  'left_event': <utils.Event at 0x7f0aec5e1e50>,\n",
       "  'right_event': <utils.Event at 0x7f0d0ca44e50>}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_data_instances(sent_ls, event_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f013f03f",
   "metadata": {},
   "source": [
    "# # Prepare Examples Dataset, save to Pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd454433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   id = coref-spanbert\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_model_name = coref\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   display_name = Coreference Resolution\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   task_id = coref\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.archive_file = coref-spanbert-large-2020.02.27.tar.gz\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.training_config = coref/coref_spanbert_large.jsonnet\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.description = The basic outline of this model is to get an embedded representation of each span in the document. These span representations are scored  and used to prune away spans that are unlikely to occur in a coreference  cluster. For the remaining spans, the model decides which antecedent span (if any) they are coreferent with. The resulting coreference links, after applying transitivity, imply a clustering of the spans in the document. The GloVe embeddings in the original paper have been substituted with SpanBERT embeddings.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.short_description = Higher-order coref with coarse-to-fine inference (with SpanBERT embeddings).\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.developed_by = Lee et al\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contributed_by = Zhaofeng Wu\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.date = 2020-02-27\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.version = 2\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.model_type = SpanBERT\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Lee2018HigherorderCR,\n",
      "title={Higher-order Coreference Resolution with Coarse-to-fine Inference},\n",
      "author={Kenton Lee and Luheng He and L. Zettlemoyer},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2018}}\n",
      "\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.title = Higher-order Coreference Resolution with Coarse-to-fine Inference\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:4891749\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.model_performance_measures = CoNLL coref scores and Mention Recall\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Ontonotes 5.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = The Coreference model was evaluated on the CoNLL 2012 dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. To compile the data in the right format for evaluating the Coreference model, please see scripts/compile_coref_data.sh. This script requires the Ontonotes 5.0 dataset, available on the LDC website.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.name = Ontonotes 5.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.notes = The Coreference model was evaluated on the CoNLL 2012 dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. To compile the data in the right format for evaluating the Coreference model, please see scripts/compile_coref_data.sh. This script requires the Ontonotes 5.0 dataset, available on the LDC website.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   id = generation-bart\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_model_name = bart\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   display_name = BART\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   task_id = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.archive_file = bart-2020.07.25.tar.gz\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.training_config = generation/bart_cnn_dm.jsonnet\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.description = The BART model here uses a language modeling head, and therefore can be used for generation. The BART encoder, implemented as a `Seq2SeqEncoder`, which assumes it operates on already embedded inputs.  This means that we remove the token and position embeddings from BART in this module.  For the typical use case of using BART to encode inputs to your model (where we include the token and position embeddings from BART), you should use `PretrainedTransformerEmbedder(bart_model_name, sub_module=\"encoder\")` instead of this.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.short_description = BART with a language model head for generation.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.developed_by = Lewis et al\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.date = 2020-07-25\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.model_type = BART\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Lewis2020BARTDS,\n",
      "title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},\n",
      "author={M. Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and A. Mohamed and Omer Levy and Ves Stoyanov and L. Zettlemoyer},\n",
      "booktitle={ACL},\n",
      "year={2020}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.title = BART: Denosing Sequence-to-Sequence Pre-training for Natural Language Generation,Translation, and Comprehension\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:204960716\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.model_performance_measures = ROUGE and BLEU\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.name = CNN/DailyMail\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://github.com/abisee/cnn-dailymail\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.name = CNN/DailyMail\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.notes = Please download the data from the url provided.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.url = https://github.com/abisee/cnn-dailymail\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   id = glove-sst\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_model_name = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   display_name = GLoVe-LSTM\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   task_id = sentiment-analysis\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.archive_file = basic_stanford_sentiment_treebank-2020.06.09.tar.gz\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.training_config = classification/basic_stanford_sentiment_treebank.jsonnet\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.description = This model uses GloVe embeddings and is trained on the binary classification setting of the Stanford Sentiment Treebank. It achieves about 87% on the test set.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.short_description = LSTM binary classifier with GloVe embeddings.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.developed_by = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.date = 2020-06-09\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.model_type = LSTM\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Stanford Sentiment Treebank\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/test.txt\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.name = Stanford Sentiment Treebank\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/train.txt\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.preprocessing = Binary classification setting\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = Accuracy: 87% on SST test set.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   id = lm-masked-language-model\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_model_name = masked_language_model\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   display_name = BERT-based Masked Language Model\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   task_id = masked-language-modeling\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.archive_file = bert-masked-lm-2020-10-07.tar.gz\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.training_config = lm/bidirectional_language_model.jsonnet\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.description = The `MaskedLanguageModel` embeds some input tokens (including some which are masked), contextualizes them, then predicts targets for the masked tokens, computing a loss against known targets.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.short_description = BERT-based masked language model\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.developed_by = Devlin et al\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.date = 2020-10-07\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.model_type = BERT\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Devlin2019BERTPO,\n",
      "title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},\n",
      "author={J. Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.title = BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:52967399\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.model_performance_measures = Perplexity\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset = BooksCorpus (800M words) and English Wikipedia (2,500M words).\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset = BooksCorpus (800M words) and English Wikipedia (2,500M words).\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.motivation = Document-level corpus is used rather than shuffled sentence-level corpus, to extract long contiguous sequences.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.preprocessing = For Wikipedia, text passages are extracted and lists, tables, and headers are ignored.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = BERT demonstrates gender bias in that it thinks the doctor is more likely a man ('his') than a woman ('her'). An important issue in NLP is how to understand and address such biases in our linguistic models.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = NOTE: This was developed for use in a demo, not for training.  It's possible that it will still work for training a masked LM, but it is very likely that some other code would be much more efficient for that.  This `does` compute correct gradients of the loss, because we use that in our demo, so in principle it should be able to train a model, we just don't necessarily endorse that use.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   id = lm-next-token-lm-gpt2\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_model_name = next_token_lm\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   display_name = GPT2-based Next Token Language Model\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   task_id = language-modeling\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.archive_file = gpt2-next-word-lm-2020.06.30.tar.gz\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.training_config = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.description = This is the public 345M parameter OpenAI GPT-2 language model for generating sentences. The model embeds some input tokens, contextualizes them, then predicts the next word, computing a loss against known target. \n",
      "If `BeamSearch` is given, this model will predict a sequence of next tokens.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.short_description = OpenAI's GPT-2 language model that generates the next token.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.developed_by = Radford et al\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.date = 2020-06-30\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.model_type = GPT2\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Radford2019LanguageMA,\n",
      "title={Language Models are Unsupervised Multitask Learners},\n",
      "author={A. Radford and Jeffrey Wu and R. Child and David Luan and Dario Amodei and Ilya Sutskever},\n",
      "year={2019}}\n",
      "\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.title = Language Models are Unsupervised Multitask Learners\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:160025533\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.model_performance_measures = Perplexity\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.name = WebText corpus\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://github.com/openai/gpt-2-output-dataset\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.name = WebText corpus\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.url = https://github.com/openai/gpt-2-output-dataset\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.motivation = WebText emphasizes document quality. Only human-curated/filtered documents are scraped. Reddit outbound links which receive at least 3 karma points are taken as a proxy for human filtered webpages that are interesting.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.preprocessing = Dragnet and [Newspaper](https://github.com/codelucas/newspaper) content extractors are used. Wikipedia articles are removed.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   id = mc-roberta-commonsenseqa\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_model_name = transformer_mc\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_predictor_name = transformer_mc\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   display_name = RoBERTa Common Sense QA\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   task_id = mc\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.archive_file = commonsenseqa.2020-07-08.tar.gz\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.training_config = mc/commonsenseqa.jsonnet\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.short_description = RoBERTa-based multiple choice model for CommonSenseQA.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.developed_by = Liu et al\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.date = 2020-07-08\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.model_type = RoBERTa large\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.name = CommonSenseQA (validation set)\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://github.com/jonathanherzig/commonsenseqa\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.name = CommonSenseQA (train set)\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.notes = Please download the data from the url provided.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.url = https://github.com/jonathanherzig/commonsenseqa\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   id = mc-roberta-piqa\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_model_name = transformer_mc\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_predictor_name = transformer_mc\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   display_name = Physical Interaction Question Answering\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   task_id = mc\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.archive_file = piqa.2020-07-08.tar.gz\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.training_config = mc/piqa.jsonnet\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.short_description = RoBERTa-based multiple choice model for PIQA.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.developed_by = Devlin et al\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.date = 2020-07-08\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.model_type = RoBERTa large\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.name = PIQA (validation set)\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://yonatanbisk.com/piqa/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.name = PIQA (train set)\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.notes = Please download the data from the url provided.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.url = https://yonatanbisk.com/piqa/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   id = mc-roberta-swag\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_model_name = transformer_mc\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_predictor_name = transformer_mc\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   display_name = RoBERTa SWAG\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   task_id = mc\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.archive_file = swag.2020-07-08.tar.gz\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.training_config = mc/swag.jsonnet\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.description = This is a multiple choice model patterned after the BERT architecture. It calculates a score for each sequence on top of the CLS token, and then chooses the alternative with the highest score.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.short_description = RoBERTa-based multiple choice model for SWAG.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.developed_by = Devlin et al\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.date = 2020-07-08\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.model_type = RoBERTa large\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.model_performance_measures = The chosen metric is accuracy, since it is a multiple choice model.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.name = SWAG (validation set)\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://rowanzellers.com/swag/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.name = SWAG (train set)\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.notes = Please download the data from the url provided.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.url = https://rowanzellers.com/swag/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   id = pair-classification-decomposable-attention-elmo\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_model_name = decomposable_attention\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_predictor_name = textual_entailment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   display_name = ELMo-based Decomposable Attention\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   task_id = textual_entailment\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.archive_file = decomposable-attention-elmo-2020.04.09.tar.gz\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.training_config = decomposable_attention_elmo.jsonnet\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.description = This `Model` implements the Decomposable Attention model described in [A Decomposable Attention Model for Natural Language Inference](https://api.semanticscholar.org/CorpusID:8495258) by Parikh et al., 2016, with some optional enhancements before the decomposable attention actually happens.  Parikh's original model allowed for computing an \"intra-sentence\" attention before doing the decomposable entailment step.  We generalize this to any `Seq2SeqEncoder` that can be applied to the premise and/or the hypothesis before computing entailment.\n",
      "\n",
      "The basic outline of this model is to get an embedded representation of each word in thepremise and hypothesis, align words between the two, compare the aligned phrases, and make a final entailment decision based on this aggregated comparison.  Each step in this process uses a feedforward network to modify the representation.\n",
      "\n",
      "This model uses ELMo embeddings.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.short_description = The decomposable attention model (Parikh et al, 2017) combined with ELMo embeddings trained on SNLI.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.developed_by = Parikh et al\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.date = 2020-04-09\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.model_type = Seq2Seq\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Parikh2016ADA,\n",
      "title={A Decomposable Attention Model for Natural Language Inference},\n",
      "author={Ankur P. Parikh and Oscar T{\"a}ckstr{\"o}m and Dipanjan Das and Jakob Uszkoreit},\n",
      "journal={ArXiv},\n",
      "year={2016},\n",
      "volume={abs/1606.01933}}\n",
      "\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.title = A Decomposable Attention Model for Natural Language Inference\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:8495258\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   id = pair-classification-esim\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_model_name = esim\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_predictor_name = textual_entailment\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   display_name = Enhanced LSTM for Natural Language Inference\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   task_id = textual_entailment\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.archive_file = esim-elmo-2020.11.11.tar.gz\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.training_config = esim.jsonnet\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.description = This `Model` implements the ESIM model, which is a sequential neural inference model based on chain LSTMs.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.short_description = Enhanced LSTM trained on SNLI.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.developed_by = Chen et al\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.date = 2020-04-09\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.model_type = LSTM\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Chen2017EnhancedLF,\n",
      "title={Enhanced LSTM for Natural Language Inference},\n",
      "author={Qian Chen and Xiao-Dan Zhu and Z. Ling and Si Wei and Hui Jiang and Diana Inkpen},\n",
      "booktitle={ACL},\n",
      "year={2017}}\n",
      "\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.title = Enhanced LSTM for Natural Language Inference\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:34032948\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_users = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   id = pair-classification-roberta-mnli\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_model_name = basic_classifier\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_predictor_name = textual_entailment\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   display_name = RoBERTa MNLI\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   task_id = textual_entailment\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.archive_file = mnli-roberta-2020-07-29.tar.gz\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.training_config = pair_classification/mnli_roberta.jsonnet\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.description = This `Model` implements a basic text classifier. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.short_description = RoBERTa finetuned on MNLI.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.developed_by = Liu et al\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.date = 2020-07-29\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.model_type = RoBERTa\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Multi-genre Natural Language Inference (MultiNLI) dev set\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/multinli/multinli_1.0_dev_mismatched.jsonl\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://cims.nyu.edu/~sbowman/multinli/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.name = Multi-genre Natural Language Inference (MultiNLI) train set\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/multinli/multinli_1.0_train.jsonl\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.url = https://cims.nyu.edu/~sbowman/multinli/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   id = pair-classification-roberta-snli\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_model_name = basic_classifier\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_predictor_name = textual_entailment\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   display_name = RoBERTa SNLI\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   task_id = textual_entailment\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.archive_file = snli-roberta-2020-07-29.tar.gz\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.training_config = pair_classification/snli_roberta.jsonnet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.description = This `Model` implements a basic text classifier. The text is embedded into a text field using a RoBERTa-large model. The resulting sequence is pooled using a cls_pooler `Seq2VecEncoder` and then passed to a linear classification layer, which projects into the label space.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.short_description = RoBERTa finetuned on SNLI.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.developed_by = Liu et al\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.date = 2020-07-29\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.model_type = RoBERTa\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Stanford Natural Language Inference (SNLI) dev set\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_test.jsonl\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.name = Stanford Natural Language Inference (SNLI) train set\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/snli/snli_1.0_train.jsonl\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.url = https://nlp.stanford.edu/projects/snli/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   id = rc-bidaf-elmo\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_model_name = bidaf\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   display_name = ELMo-BiDAF\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   task_id = rc\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.archive_file = bidaf-elmo.2021-02-11.tar.gz\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.training_config = rc/bidaf_elmo.jsonnet\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.description = This is an implementation of the BiDAF model with ELMo embeddings. The basic layout is pretty simple: encode words as a combination of word embeddings and a character-level encoder, pass the word representations through a bi-LSTM/GRU, use a matrix of attentions to put question information into the passage word representations (this is the only part that is at all non-standard), pass this through another few layers of bi-LSTMs/GRUs, and do a softmax over span start and span end.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.short_description = BiDAF model with ELMo embeddings instead of GloVe.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.developed_by = Seo et al\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.date = 2020-03-19\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.model_type = BiDAF\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Seo2017BidirectionalAF,\n",
      "title={Bidirectional Attention Flow for Machine Comprehension},\n",
      "author={Minjoon Seo and Aniruddha Kembhavi and Ali Farhadi and Hannaneh Hajishirzi},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01603}}\n",
      "\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.title = Bidirectional Attention Flow for Machine Comprehension\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:8535316\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.model_performance_measures = Start, end and overall span accuracy, Exact Match, F1 score\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.name = SQuAD dev set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v1.1.json\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.name = SQuAD training set\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v1.1.json\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = On the validation set:\n",
      "Start accuracy: 66%\n",
      "End accuracy: 69%\n",
      "Overall span accuracy: 57%\n",
      "Exact match: 71%\n",
      "F1: 80%\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = This model is based on ELMo. ELMo is not deterministic, meaning that you will see slight differences every time you run it. Also, ELMo likes to be warmed up, so we recommend processing dummy input before processing real workloads with it.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   id = rc-bidaf\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_model_name = bidaf\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   display_name = BiDAF\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   task_id = rc\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.archive_file = bidaf-model-2020.03.19.tar.gz\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.training_config = rc/bidaf.jsonnet\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.description = This is an implementation of the BiDAF model with GloVe embeddings. The basic layout is pretty simple: encode words as a combination of word embeddings and a character-level encoder, pass the word representations through a bi-LSTM/GRU, use a matrix of attentions to put question information into the passage word representations (this is the only part that is at all non-standard), pass this through another few layers of bi-LSTMs/GRUs, and do a softmax over span start and span end.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.short_description = BiDAF model with GloVe embeddings.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.developed_by = Seo et al\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.date = 2020-03-19\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.model_type = BiDAF\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Seo2017BidirectionalAF,\n",
      "title={Bidirectional Attention Flow for Machine Comprehension},\n",
      "author={Minjoon Seo and Aniruddha Kembhavi and Ali Farhadi and Hannaneh Hajishirzi},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01603}}\n",
      "\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.title = Bidirectional Attention Flow for Machine Comprehension\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:8535316\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.model_performance_measures = Start, end, and overall span accuracy, Exact Match, F1 score\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.name = SQuAD dev set\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v1.1.json\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.name = SQuAD training set\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v1.1.json\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = On the validation set:\n",
      "Start accuracy: 61%\n",
      "End accuracy: 66%\n",
      "Overall span accuracy: 52%\n",
      "Exact match: 66%\n",
      "F1: 76%\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   id = rc-naqanet\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_model_name = naqanet\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   display_name = Numerically Augmented QA Net\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   task_id = rc\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.archive_file = naqanet-2020.02.19.tar.gz\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.training_config = rc/naqanet.jsonnet\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.overrides = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.description = An augmented version of QANet model with some rudimentary numerical reasoning abilities. The main idea here is that instead of just predicting a passage span after doing all of the QANet modeling stuff, we add several different 'answer abilities': predicting a span from the question, predicting a count, or predicting an arithmetic expression.  Near the end of the QANet model, we have a variable that predicts what kind of answer type we need, and each branch has separate modeling logic to predict that answer type.  We then marginalize over all possible ways of getting to the right answer through each of these answer types.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.short_description = An augmented version of QANet that adds rudimentary numerical reasoning ability, trained on DROP (Dua et al., 2019), as published in the original DROP paper.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.developed_by = Dua et al\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.date = 2020-02-19\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.model_type = QANet\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Dua2019DROPAR,\n",
      "title={DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs},\n",
      "author={Dheeru Dua and Yizhong Wang and Pradeep Dasigi and Gabriel Stanovsky and Sameer Singh and Matt Gardner},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.title = DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:67855846\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.model_performance_measures = Exact Match and F1-score\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.name = DROP\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip!drop_dataset/drop_dataset_dev.json\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://allennlp.org/drop\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.name = DROP\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/drop/drop_dataset.zip!drop_dataset/drop_dataset_train.json\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.url = https://allennlp.org/drop\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   id = rc-nmn\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_model_name = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   display_name = Neural Module Network (NMN)\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   task_id = rc\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.archive_file = drop-nmn-2020.04.04.tar.gz\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.training_config = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.description = A neural module network trained on DROP.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.short_description = A neural module network trained on DROP.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.developed_by = Andreas et al\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.date = 2020-04-04\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.model_type = Neural Module Network\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Andreas2016NeuralMN,\n",
      "title={Neural Module Networks},\n",
      "author={Jacob Andreas and Marcus Rohrbach and Trevor Darrell and D. Klein},\n",
      "journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
      "year={2016},\n",
      "pages={39-48}}\n",
      "\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.title = Neural Module Networks\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:5276660\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.model_performance_measures = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.name = DROP\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.url = https://allennlp.org/drop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   id = rc-transformer-qa\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_model_name = transformer_qa\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   display_name = Transformer QA\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   task_id = rc\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.archive_file = transformer-qa.2021-02-11.tar.gz\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.training_config = rc/transformer_qa.jsonnet\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.description = The model implements a reading comprehension model patterned after the proposed model in [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al, 2018)](https://api.semanticscholar.org/CorpusID:52967399), with improvements borrowed from the SQuAD model in the transformers project. It predicts start tokens and end tokens with a linear layer on top of word piece embeddings.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.short_description = A reading comprehension model patterned after the proposed model in Devlin et al, with improvements borrowed from the SQuAD model in the transformers project\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.developed_by = Devlin et al\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld and Evan Pete Walsh\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.date = 2020-10-03\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.version = 2\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.model_type = RoBERTa\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and L. Zettlemoyer and V. Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.model_performance_measures = F1-score, Span Accuracy, Exact Match\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.name = SQuAD dev set\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-dev-v2.0.json\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/2.0/dev/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.name = SQuAD training set\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://s3-us-west-2.amazonaws.com/allennlp/datasets/squad/squad-train-v2.0.json\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.dataset.url = https://rajpurkar.github.io/SQuAD-explorer/explore/2.0/dev/\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.motivation = For the pretrained RoBERTa model, document-level corpora were used rather than a shuffled sentence-level corpus such as the Billion Word Benchmark (Chelba et al., 2013) in order to extract long contiguous sequences\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   training_data.preprocessing = For the pretrained RoBERTa model, only the text passages were extracted from English Wikipedia; lists, tables, and headers were ignored.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 88%\n",
      "Exact match: 84%\n",
      "These are metrics using the official evaluation. Note that the metrics that the model produces while training are calculated on a per-instance basis only. Since there could be more than one instance per question, these metrics are not the official numbers on the SQuAD task. To get official numbers, run the evaluation script at allennlp_models/rc/tools/transformer_qa_eval.py.\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:15 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   id = roberta-sst\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_model_name = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   display_name = RoBERTa large\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   task_id = sentiment-analysis\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.archive_file = sst-roberta-large-2020.06.08.tar.gz\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.training_config = classification/stanford_sentiment_treebank_roberta.jsonnet\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.description = This model is trained on RoBERTa large with the binary classification setting of the Stanford Sentiment Treebank. It achieves 95.11% accuracy on the test set.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.short_description = RoBERTa-based binary classifier for Stanford Sentiment Treebank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.developed_by = Devlin et al\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contributed_by = Zhaofeng Wu\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.date = 2020-06-08\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.model_type = RoBERTa large\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Liu2019RoBERTaAR,\n",
      "title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},\n",
      "author={Y. Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and M. Lewis and Luke Zettlemoyer and Veselin Stoyanov},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1907.11692}}\n",
      "\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.title = RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al)\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:198953378\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Stanford Sentiment Treebank\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/test.txt\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.name = Stanford Sentiment Treebank\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.processed_url = https://allennlp.s3.amazonaws.com/datasets/sst/train.txt\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.url = https://nlp.stanford.edu/sentiment/treebank.html\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.preprocessing = Binary classification setting\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = Accuracy: 95.11% on SST test set.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   id = semparse-nlvr\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_model_name = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   display_name = NLVR Semantic Parsing\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   task_id = semparse-nlvr\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.archive_file = https://allennlp.s3.amazonaws.com/models/nlvr-erm-model-2020.02.10-rule-vocabulary-updated.tar.gz\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.training_config = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.description = The model is a semantic parser trained on Cornell NLVR.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.short_description = The model is a semantic parser trained on Cornell NLVR.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.developed_by = Dasigi et al\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.date = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.version = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.model_type = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.model_performance_measures = Denotation accuracy and consistency\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Cornell NLVR\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.url = http://lil.nlp.cornell.edu/nlvr/\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.name = Cornell NLVR\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.notes = Please download the data from the url provided.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.url = http://lil.nlp.cornell.edu/nlvr/\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   id = semparse-text-to-sql\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_model_name = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   display_name = Text to SQL (ATIS)\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   task_id = semparse-text-to-sql\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.archive_file = https://allennlp.s3.amazonaws.com/models/atis-parser-2020.02.10.tar.gz\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.training_config = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.description = This model is an implementation of an encoder-decoder architecture with LSTMs and constrained type decoding trained on the ATIS dataset. This model is still a proof-of-concept of what you can do with semantic parsing in AllenNLP and its performance is not state-of-the-art (this naive model gets around 40% exact denotation accuracy on the contextual ATIS dataset).\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.short_description = This model is an implementation of an encoder-decoder architecture with LSTMs and constrained type decoding trained on the ATIS dataset.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.developed_by = Dasigi et al\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.date = 2020-02-10\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.model_type = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.model_performance_measures = 1. `exact_match`; the percentage of the time that our best output action sequence matches the SQL query exactly.\n",
      "2. `denotation_acc`; the percentage of examples where we get the correct denotation.\n",
      "3. `valid_sql_query`; the percentage of time that decoding actually produces avalid SQL query.\n",
      "4. `action_similarity`; how similar the action sequence predicted is to the actual action sequence.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.name = ATIS\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://api.semanticscholar.org/CorpusID:1094063\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.name = ATIS\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.notes = Please download the data from the url provided.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.url = https://api.semanticscholar.org/CorpusID:1094063\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   id = semparse-wikitables\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_model_name = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   display_name = WikiTables Semantic Parsing\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   task_id = semparse-tabular\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.archive_file = wikitables-model-2020.02.10.tar.gz\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.training_config = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.description = The model is a semantic parser trained on WikiTableQuestions.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.short_description = The model is a semantic parser trained on WikiTableQuestions.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.developed_by = Dasigi et al\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.date = 2020-02-10\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.model_type = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Dasigi2019IterativeSF,\n",
      "title={Iterative Search for Weakly Supervised Semantic Parsing},\n",
      "author={Pradeep Dasigi and Matt Gardner and Shikhar Murty and Luke Zettlemoyer and E. Hovy},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2019}}\n",
      "\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.title = Iterative Search for Weakly Supervised Semantic Parsing\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:174799945\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.license = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.model_performance_measures = 1. `lf_retrieval_acc`; the percentage of the time that our best output action sequence is in the set of action sequences provided by offline search.\n",
      "2. `denotation_acc`; the percentage of examples where we get the correct denotation.\n",
      "3. `lf_percent`; the percentage of time that decoding actually produces a finished logical form\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.name = WikiTableQuestions\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://ppasupat.github.io/WikiTableQuestions/\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.name = WikiTableQuestions\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.notes = Please download the data from the url provided.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.url = https://ppasupat.github.io/WikiTableQuestions/\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   id = structured-prediction-biaffine-parser\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_model_name = biaffine_parser\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   display_name = Deep Biaffine Attention for Neural Dependency Parsing\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   task_id = dependency-parsing\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.archive_file = biaffine-dependency-parser-ptb-2020.04.06.tar.gz\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.training_config = structured_prediction/dependency_parser.jsonnet\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.description = This dependency parser follows the model of [Deep Biaffine Attention for Neural Dependency Parsing (Dozat and Manning, 2016)](https://api.semanticscholar.org/CorpusID:7942973) .\n",
      "\n",
      "Word representations are generated using a bidirectional LSTM, followed by separate biaffine classifiers for pairs of words, predicting whether a directed arc exists between the two words and the dependency label the arc should have. Decoding can either be done greedily, or the optimal Minimum Spanning Tree can be decoded using Edmond's algorithm by viewing the dependency tree as a MST on a fully connected graph, where nodes are words and edges are scored dependency arcs.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.short_description = A neural model for dependency parsing using biaffine classifiers on top of a bidirectional LSTM.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.developed_by = Dozat et al\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.date = 2020-04-06\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.model_type = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Dozat2017DeepBA,\n",
      "title={Deep Biaffine Attention for Neural Dependency Parsing},\n",
      "author={Timothy Dozat and Christopher D. Manning},\n",
      "journal={ArXiv},\n",
      "year={2017},\n",
      "volume={abs/1611.01734}}\n",
      "\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.title = Deep Biaffine Attention for Neural Dependency Parsing (Dozat and Manning, 2016)\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:7942973\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.model_performance_measures = Attachment scores and exact matches (UAS, LAS, UEM, LEM)\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.name = PTB 3.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = The dependency parser was evaluated on the Penn Tree Bank dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can download the PTB data from the LDC website.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.name = PTB 3.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.notes = The dependency parser was evaluated on the Penn Tree Bank dataset. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can download the PTB data from the LDC website.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = The parser achieves 95.57% and 94.44% unlabeled and labeled attachement score using gold POS tags. For predicted POS tags, it achieves 94.81% UAS and 92.86% LAS respectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   id = structured-prediction-constituency-parser\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_model_name = constituency_parser\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   display_name = Constituency Parser with ELMo embeddings\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   task_id = constituency-parsing\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.archive_file = elmo-constituency-parser-2020.02.10.tar.gz\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.training_config = structured-prediction/constituency_parser_elmo.jsonnet\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.description = This is an implementation of a minimal neural model for constituency parsing based on an independent scoring of labels and spans. This `SpanConstituencyParser` simply encodes a sequence of text with a stacked `Seq2SeqEncoder`, extracts span representations using a `SpanExtractor`, and then predicts a label for each span in the sequence. These labels are non-terminal nodes in a constituency parse tree, which we then greedily reconstruct. The model uses ELMo embeddings, which are completely character-based and improves single model performance from 92.6 F1 to 94.11 F1 on the Penn Treebank, a 20% relative error reduction.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.short_description = Constituency parser with character-based ELMo embeddings\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.developed_by = Joshi et al\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.date = 2020-02-10\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.model_type = Seq2SeqEncoder\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Joshi2018ExtendingAP,\n",
      "title={Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples},\n",
      "author={V. Joshi and Matthew E. Peters and Mark Hopkins},\n",
      "booktitle={ACL},\n",
      "year={2018}}\n",
      "\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.title = Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:21712653\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.model_performance_measures = Precision, Recall and F1-score for parse trees (EVALB_bracketing_scorer)\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.name = PTB 3.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Please download the data from the url provided.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.name = PTB 3.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.notes = Please download the data from the url provided.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC99T42\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = 94.11 F1 score\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   id = structured-prediction-srl-bert\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_model_name = srl_bert\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   display_name = SRL BERT\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   task_id = srl\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.archive_file = structured-prediction-srl-bert.2020.12.15.tar.gz\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.training_config = structured_prediction/bert_base_srl.jsonnet\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.description = An implementation of a BERT based model (Shi et al, 2019) with some modifications (no additional parameters apart from a linear classification layer), which is currently the state of the art single model for English PropBank SRL (Newswire sentences). It achieves 86.49 test F1 on the Ontonotes 5.0 dataset.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.short_description = A BERT based model (Shi et al, 2019) with some modifications (no additional parameters apart from a linear classification layer)\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.developed_by = Shi et al\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.date = 2020-09-03\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.model_type = BERT\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Shi2019SimpleBM,\n",
      "title={Simple BERT Models for Relation Extraction and Semantic Role Labeling},\n",
      "author={Peng Shi and Jimmy Lin},\n",
      "journal={ArXiv},\n",
      "year={2019},\n",
      "volume={abs/1904.05255}}\n",
      "\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.title = Simple BERT Models for Relation Extraction and Semantic Role Labeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:131773936\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.model_performance_measures = Precision, recall and F1-score\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Ontonotes 5.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = We cannot release this data due to licensing restrictions.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.name = Ontonotes 5.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.notes = We cannot release this data due to licensing restrictions.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = 86.49 test F1 on the Ontonotes 5.0 dataset\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   id = structured-prediction-srl\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_model_name = srl\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   display_name = Open Information Extraction\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   task_id = srl\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.archive_file = openie-model.2020.03.26.tar.gz\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.training_config = structured-prediction/srl.jsonnet\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.description = A reimplementation of a deep BiLSTM sequence prediction model (Stanovsky et al., 2018).\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.short_description = A reimplementation of a deep BiLSTM sequence prediction model (Stanovsky et al., 2018)\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.developed_by = Stanovsky et al\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.date = 2020-03-26\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.model_type = BiLSTM\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Stanovsky2018SupervisedOI,\n",
      "title={Supervised Open Information Extraction},\n",
      "author={Gabriel Stanovsky and Julian Michael and Luke Zettlemoyer and I. Dagan},\n",
      "booktitle={NAACL-HLT},\n",
      "year={2018}}\n",
      "\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.title = Supervised Open Information Extraction\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:44145304\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.model_performance_measures = CoNLL SRL metrics\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.name = OIE2016, WEB and NYT, PENN\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = The Open Information extractor was evaluated on the OIE2016 corpus. Unfortunately we cannot release this data due to licensing restrictions by the LDC. You can get the data on the corpus homepage.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://github.com/gabrielStanovsky/oie-benchmark\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.name = All Words Open IE\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.url = https://github.com/gabrielStanovsky/supervised-oie/tree/master/data\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   id = tagging-elmo-crf-tagger\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_model_name = crf_tagger\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   display_name = ELMo-based Named Entity Recognition\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   task_id = ner\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.archive_file = ner-elmo.2021-02-12.tar.gz\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.training_config = tagging/ner_elmo.jsonnet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.description = This model is the baseline model described in [Semi-supervised sequence tagging with bidirectional language models](https://api.semanticscholar.org/CorpusID:7197241). It uses a Gated Recurrent Unit (GRU) character encoder as well as a GRU phrase encoder, and it starts with pretrained GloVe vectors for its token embeddings. It was trained on the CoNLL-2003 NER dataset.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.short_description = NER tagger using a Gated Recurrent Unit (GRU) character encoder as well as a GRU phrase encoder, with GloVe embeddings.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.developed_by = Peters et al\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.date = 2020-02-10\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.model_type = Gated Recurrent Unit (GRU)\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Peters2017SemisupervisedST,\n",
      "title={Semi-supervised sequence tagging with bidirectional language models},\n",
      "author={Matthew E. Peters and Waleed Ammar and Chandra Bhagavatula and R. Power},\n",
      "booktitle={ACL},\n",
      "year={2017}}\n",
      "\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.title = Semi-supervised sequence tagging with bidirectional language models\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:7197241\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.name = CoNLL-2003 NER dataset\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = The NER model was evaluated on the CoNLL-2003 NER dataset. Unfortunately we cannot release this data due to licensing restrictions.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = path/to/dataset\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://www.clips.uantwerpen.be/conll2003/ner/\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.name = CoNLL-2003 NER dataset\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.notes = The NER model was trained on the CoNLL-2003 NER dataset. Unfortunately we cannot release this data due to licensing restrictions.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.processed_url = /path/to/dataset\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.url = https://www.clips.uantwerpen.be/conll2003/ner/\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = Achieves 99% accuracy and 96% F1 on the CoNLL-2003 validation set.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = This model is based on ELMo. ELMo is not deterministic, meaning that you will see slight differences every time you run it. Also, ELMo likes to be warmed up, so we recommend processing dummy input before processing real workloads with it.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   id = tagging-fine-grained-crf-tagger\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_model_name = crf_tagger\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   display_name = Fine Grained Named Entity Recognition\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   task_id = ner\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.archive_file = fine-grained-ner.2021-02-11.tar.gz\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.training_config = tagging/fine-grained-ner.jsonnet\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.description = This model identifies a broad range of 16 semantic types in the input text. It is a reimplementation of Lample (2016) and uses a biLSTM with a CRF layer, character embeddings and ELMo embeddings.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.short_description = This model identifies a broad range of 16 semantic types in the input text. It is a reimplementation of Lample (2016) and uses a biLSTM with a CRF layer, character embeddings and ELMo embeddings.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.developed_by = Lample et al\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.date = 2020-06-24\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.model_type = BiLSTM\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@article{Lample2016NeuralAF,\n",
      "title={Neural Architectures for Named Entity Recognition},\n",
      "author={Guillaume Lample and Miguel Ballesteros and Sandeep Subramanian and K. Kawakami and Chris Dyer},\n",
      "journal={ArXiv},\n",
      "year={2016},\n",
      "volume={abs/1603.01360}}\n",
      "\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.title = Neural Architectures for Named Entity Recognition\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:6042994\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Ontonotes 5.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = /path/do/dataset\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.name = Ontonotes 5.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.processed_url = /path/do/dataset\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = On the validation set:\n",
      "Accuracy: 97%\n",
      "F1: 88%\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   id = tagging-fine-grained-transformer-crf-tagger\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_model_name = crf_tagger\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_predictor_name = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   display_name = Fine Grained Named Entity Recognition with Transformer\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   task_id = ner\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.archive_file = fgner-transformer.2021-02-11.tar.gz\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.training_config = tagging/fgner_transformer.jsonnet\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.description = Fine-grained NER model\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.short_description = Fine-grained NER model\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.developed_by = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contributed_by = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.date = 2020-07-14\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.model_type = Transformer\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_uses = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy and Span-based F1 metric\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Ontonotes 5.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.name = Ontonotes 5.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.notes = Unfortunately we cannot release this data due to licensing restrictions.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.url = https://catalog.ldc.upenn.edu/LDC2013T19\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = On the validation set:\n",
      "Accuracy: 98%\n",
      "F1: 88%\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   id = ve-vilbert\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_model_name = visual-entailment\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_predictor_name = vilbert_ve\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   display_name = Visual Entailment\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   task_id = ve\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.archive_file = visual-entailment-torchvision-2020.12.23.tar.gz\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.training_config = vilbert_ve_pretrained.jsonnet\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==1.0.0 allennlp-models==1.0.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.description = This model is based on the ViLBERT architecture. The image features are obtained using the ResNet backbone and Faster RCNN (region detection).\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.short_description = ViLBERT-based model for Visual Entailment.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.developed_by = Lu et al\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contributed_by = Akshita Bhagia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.date = 2020-12-23\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.model_type = ViLBERT based on BERT large\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.model_performance_measures = Accuracy and F1-score\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.name = Stanford Natural Language Inference - Visual Entailment(SNLI-VE) dev set\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://github.com/necla-ml/SNLI-VE\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.name = Stanford Natural Language Inference - Visual Entailment(SNLI-VE) train set\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.url = https://github.com/necla-ml/SNLI-VE\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = This model is trained on the original SNLI-VE dataset. [Subsequent work](https://api.semanticscholar.org/CorpusID:215415945) has found that an estimated 31% of `neutral` labels in the dataset are incorrect. The `e-SNLI-VE-2.0` dataset contains the re-annotated validation and test sets.\n",
      "04/13/2022 12:02:16 - WARNING - allennlp.common.model_card -   visual-entailment is not a registered model.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   id = vqa-vilbert\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_model_name = vqa_vilbert\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_class = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   registered_predictor_name = vilbert_vqa\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   display_name = ViLBERT - Visual Question Answering\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   task_id = vqa\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.archive_file = vilbert-vqa-pretrained.2021-02-11.tar.gz\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.training_config = vision/vilbert_vqa_pretrained.jsonnet\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.install_instructions = pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_usage.overrides = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.short_description = ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.developed_by = Lu et al\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contributed_by = Dirk Groeneveld\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.date = 2020-10-01\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.version = 1\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.model_type = ViLBERT based on BERT large\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.citation = \n",
      "@inproceedings{Lu2019ViLBERTPT,\n",
      "title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n",
      "author={Jiasen Lu and Dhruv Batra and D. Parikh and Stefan Lee},\n",
      "booktitle={NeurIPS},\n",
      "year={2019}\n",
      "}\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.title = ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.paper.url = https://api.semanticscholar.org/CorpusID:199453025\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.license = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_details.contact = allennlp-contact@allenai.org\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_uses = This model is developed for the AllenNLP demo.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.primary_users = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   intended_use.out_of_scope_use_cases = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.relevant_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   factors.evaluation_factors = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.model_performance_measures = F1-metric and VQA score\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.decision_thresholds = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   metrics.variation_approaches = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.name = VQA dataset\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.notes = Evaluation requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.processed_url = balanced_real_val\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.dataset.url = https://visualqa.org/\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   evaluation_data.preprocessing = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.name = VQA dataset\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.notes = Training requires a large amount of images to be accessible locally, so we cannot provide a command you can easily copy and paste. The first time you run it, you will get an error message that tells you how to get the rest of the data.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.processed_url = balanced_real_train\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.dataset.url = https://visualqa.org/\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.motivation = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   training_data.preprocessing = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.unitary_results = On the validation set:\n",
      "F1: 41%\n",
      "VQA: 52%.\n",
      "These scores do not match the performance in the VilBERT paper. Please contact us if you want to match those scores!\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   quantitative_analyses.intersectional_results = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_ethical_considerations.ethical_considerations = None\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.params -   model_caveats_and_recommendations.caveats_and_recommendations = None\n",
      "04/13/2022 12:02:16 - WARNING - allennlp.common.model_card -   vqa_vilbert is not a registered model.\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.plugins -   Plugin allennlp_models available\n",
      "04/13/2022 12:02:16 - INFO - filelock -   Lock 139694023440368 acquired on /home/gxu21/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3.lock\n",
      "04/13/2022 12:02:16 - INFO - allennlp.common.file_utils -   cache of https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz is up-to-date\n",
      "04/13/2022 12:02:16 - INFO - filelock -   Lock 139694023440368 released on /home/gxu21/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3.lock\n",
      "04/13/2022 12:02:16 - INFO - allennlp.models.archival -   loading archive file https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz from cache at /home/gxu21/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3\n",
      "04/13/2022 12:02:16 - INFO - allennlp.models.archival -   extracting archive file /home/gxu21/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3 to temp dir /tmp/tmpp2buylm7\n",
      "04/13/2022 12:02:19 - INFO - allennlp.common.params -   dataset_reader.type = srl\n",
      "04/13/2022 12:02:19 - INFO - allennlp.common.params -   dataset_reader.max_instances = None\n",
      "04/13/2022 12:02:19 - INFO - allennlp.common.params -   dataset_reader.manual_distributed_sharding = False\n",
      "04/13/2022 12:02:19 - INFO - allennlp.common.params -   dataset_reader.manual_multiprocess_sharding = False\n",
      "04/13/2022 12:02:19 - INFO - allennlp.common.params -   dataset_reader.token_indexers = None\n",
      "04/13/2022 12:02:19 - INFO - allennlp.common.params -   dataset_reader.domain_identifier = None\n",
      "04/13/2022 12:02:19 - INFO - allennlp.common.params -   dataset_reader.bert_model_name = bert-base-uncased\n",
      "04/13/2022 12:02:21 - INFO - allennlp.common.params -   dataset_reader.type = srl\n",
      "04/13/2022 12:02:21 - INFO - allennlp.common.params -   dataset_reader.max_instances = None\n",
      "04/13/2022 12:02:21 - INFO - allennlp.common.params -   dataset_reader.manual_distributed_sharding = False\n",
      "04/13/2022 12:02:21 - INFO - allennlp.common.params -   dataset_reader.manual_multiprocess_sharding = False\n",
      "04/13/2022 12:02:21 - INFO - allennlp.common.params -   dataset_reader.token_indexers = None\n",
      "04/13/2022 12:02:21 - INFO - allennlp.common.params -   dataset_reader.domain_identifier = None\n",
      "04/13/2022 12:02:21 - INFO - allennlp.common.params -   dataset_reader.bert_model_name = bert-base-uncased\n",
      "04/13/2022 12:02:21 - INFO - allennlp.common.params -   type = from_instances\n",
      "04/13/2022 12:02:21 - INFO - allennlp.data.vocabulary -   Loading token dictionary from /tmp/tmpp2buylm7/vocabulary.\n",
      "04/13/2022 12:02:21 - INFO - filelock -   Lock 139694023432368 acquired on /tmp/tmpp2buylm7/vocabulary/.lock\n",
      "04/13/2022 12:02:21 - INFO - filelock -   Lock 139694023432368 released on /tmp/tmpp2buylm7/vocabulary/.lock\n",
      "04/13/2022 12:02:21 - INFO - allennlp.common.params -   model.type = srl_bert\n",
      "04/13/2022 12:02:21 - INFO - allennlp.common.params -   model.regularizer = None\n",
      "04/13/2022 12:02:21 - INFO - allennlp.common.params -   model.bert_model = bert-base-uncased\n",
      "04/13/2022 12:02:21 - INFO - allennlp.common.params -   model.embedding_dropout = 0.1\n",
      "04/13/2022 12:02:21 - INFO - allennlp.common.params -   model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f0d0ca64f40>\n",
      "04/13/2022 12:02:21 - INFO - allennlp.common.params -   model.label_smoothing = None\n",
      "04/13/2022 12:02:21 - INFO - allennlp.common.params -   model.ignore_span_metric = False\n",
      "04/13/2022 12:02:21 - INFO - allennlp.common.params -   model.srl_eval_path = /home/gxu21/anaconda3/envs/newECONET/lib/python3.8/site-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -   Initializing parameters\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -   Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.embeddings.LayerNorm.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.embeddings.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.embeddings.position_embeddings.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.embeddings.token_type_embeddings.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.embeddings.word_embeddings.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.output.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.output.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.key.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.key.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.query.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.query.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.value.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.value.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.intermediate.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.intermediate.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.output.LayerNorm.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.output.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.output.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.output.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.output.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.output.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.key.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.key.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.query.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.query.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.value.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.value.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.intermediate.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.intermediate.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.output.LayerNorm.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.output.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.output.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.output.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.output.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.output.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.key.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.key.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.query.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.query.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.value.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.value.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.intermediate.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.intermediate.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.output.LayerNorm.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.output.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.output.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.output.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.output.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.output.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.key.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.key.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.query.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.query.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.value.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.value.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.intermediate.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.intermediate.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.output.LayerNorm.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.output.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.output.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.output.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.output.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.output.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.key.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.key.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.query.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.query.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.value.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.value.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.intermediate.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.intermediate.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.output.LayerNorm.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.output.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.output.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.output.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.output.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.output.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.key.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.key.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.query.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.query.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.value.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.value.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.intermediate.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.intermediate.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.output.LayerNorm.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.output.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.output.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.output.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.output.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.output.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.key.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.key.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.query.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.query.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.value.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.value.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.intermediate.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.intermediate.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.output.LayerNorm.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.output.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.output.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.output.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.output.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.output.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.key.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.key.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.query.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.query.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.value.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.value.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.intermediate.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.intermediate.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.output.LayerNorm.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.output.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.output.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.output.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.output.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.output.dense.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.key.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.key.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.query.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.query.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.value.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.value.weight\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.intermediate.dense.bias\n",
      "04/13/2022 12:02:23 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.intermediate.dense.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.output.LayerNorm.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.output.LayerNorm.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.output.dense.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.output.dense.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.output.dense.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.output.dense.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.key.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.key.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.query.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.query.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.value.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.value.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.intermediate.dense.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.intermediate.dense.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.output.LayerNorm.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.output.LayerNorm.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.output.dense.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.output.dense.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.output.dense.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.output.dense.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.key.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.key.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.query.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.query.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.value.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.value.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.intermediate.dense.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.intermediate.dense.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.output.LayerNorm.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.output.LayerNorm.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.output.dense.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.output.dense.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.output.dense.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.output.dense.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.key.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.key.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.query.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.query.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.value.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.value.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.intermediate.dense.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.intermediate.dense.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.output.LayerNorm.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.output.LayerNorm.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.output.dense.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.output.dense.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.pooler.dense.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      bert_model.pooler.dense.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      tag_projection_layer.bias\n",
      "04/13/2022 12:02:24 - INFO - allennlp.nn.initializers -      tag_projection_layer.weight\n",
      "04/13/2022 12:02:24 - INFO - allennlp.models.archival -   removing temporary unarchived model dir at /tmp/tmpp2buylm7\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from utils import * \n",
    "from get_srl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0c5723a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print the triggers: ---------  \n",
      "\n",
      "hated bomb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rel_type': 'BEFORE',\n",
       " 'rev': None,\n",
       " 'doc_dictionary': OrderedDict([('[0:1)', ('I', None)),\n",
       "              ('[2:7)', ('hated', None)),\n",
       "              ('[8:13)', ('going', None)),\n",
       "              ('[14:16)', ('to', None)),\n",
       "              ('[17:23)', ('school', None)),\n",
       "              ('[23:24)', (';', None)),\n",
       "              ('[25:27)', ('so', None)),\n",
       "              ('[27:28)', (',', None)),\n",
       "              ('[29:30)', ('i', None)),\n",
       "              ('[31:35)', ('will', None)),\n",
       "              ('[36:40)', ('bomb', None)),\n",
       "              ('[41:43)', ('my', None)),\n",
       "              ('[44:50)', ('school', None)),\n",
       "              ('[50:51)', ('!', None))]),\n",
       " 'event_labels': None,\n",
       " 'doc_id': None,\n",
       " 'left_event': <utils.Event at 0x7f0b681f1af0>,\n",
       " 'right_event': <utils.Event at 0x7f0b080f4eb0>}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sent = \"I hated going to school; so, i will bomb my school!\"\n",
    "\n",
    "\n",
    "\n",
    "def parse(sent, event1_id, event2_id):\n",
    "    od = OrderedDict()\n",
    "    \n",
    "    events = get_predicate(sent)\n",
    "#     if not events:\n",
    "#         continue\n",
    "    tokens = events[0][-1]\n",
    "    print(\"print the triggers: ---------  \\n\")\n",
    "    print(tokens[event1_id], tokens[event2_id])\n",
    "    tok_id = 0\n",
    "    event1_span, event2_span = None, None\n",
    "    for offset in range(len(sent)):\n",
    "        if tok_id ==event1_id:\n",
    "            event1_span = (offset, offset+len(tokens[tok_id])-1)\n",
    "        elif tok_id ==event2_id:\n",
    "            event2_span = (offset, offset+len(tokens[tok_id])-1)\n",
    "        if tok_id >= len(tokens):\n",
    "            break\n",
    "        tok = tokens[tok_id]\n",
    "        if sent[offset:offset+len(tok)]==tok:\n",
    "            od['['+str(offset)+':'+str(offset+len(tok)) + ')'] = (tok, None)\n",
    "            tok_id+=1\n",
    "    return od, event1_span, event2_span\n",
    "\n",
    "\n",
    "\n",
    "def create_data_instance(sent, event1_id, event2_id):\n",
    "    \"\"\"\n",
    "    sentence is a string and event spans are a list of the spans of two events\n",
    "    event1_id, event2_id are positional token id of the two event trigger tokens\n",
    "    \"\"\" \n",
    "    doc_dict,e1_span,e2_span = parse(sent, 1, 10)\n",
    "    left_event = Event(None, None, None, None, None, e1_span)\n",
    "    right_event = Event(None, None, None, None, None, e2_span)\n",
    "    v = dict()\n",
    "    v['rel_type'],v['rev'],v['doc_dictionary'],v['event_labels'],v['doc_id'],v['left_event'],v['right_event'] = \\\n",
    "    'BEFORE', None, doc_dict, None, None, left_event, right_event\n",
    "    return v\n",
    "\n",
    "\n",
    "def create_data_instances(sents, event_ids):\n",
    "    cnt = 0 \n",
    "    d = dict()\n",
    "    for sent, event_id, verb in zip(sents, event_ids, verbs):\n",
    "        v = create_data_instance(sent, event_id[0], event_id[1])\n",
    "        d['L_' + str(cnt)] = v\n",
    "        cnt+=1\n",
    "    return d\n",
    "        \n",
    "create_data_instance(sent,1,10)\n",
    "\n",
    "# parse(sent)\n",
    "# examples = create_data_instance(sent, event_spans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d745a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = create_data_instances(sents, event_spans_ls)\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aa5ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339dfbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f87ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
