{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd63eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "import transformers \n",
    "import nltk\n",
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f096350f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/07/2022 19:42:53 - INFO - allennlp.common.plugins -   Plugin allennlp_models available\n",
      "04/07/2022 19:42:53 - INFO - allennlp.common.file_utils -   cache of https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz is up-to-date\n",
      "04/07/2022 19:42:53 - INFO - allennlp.models.archival -   loading archive file https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz from cache at /home/gxu21/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3\n",
      "04/07/2022 19:42:53 - INFO - allennlp.models.archival -   extracting archive file /home/gxu21/.allennlp/cache/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3 to temp dir /tmp/tmpq7hh7fh2\n",
      "04/07/2022 19:42:55 - INFO - allennlp.common.params -   dataset_reader.type = srl\n",
      "04/07/2022 19:42:55 - INFO - allennlp.common.params -   dataset_reader.max_instances = None\n",
      "04/07/2022 19:42:55 - INFO - allennlp.common.params -   dataset_reader.manual_distributed_sharding = False\n",
      "04/07/2022 19:42:55 - INFO - allennlp.common.params -   dataset_reader.manual_multiprocess_sharding = False\n",
      "04/07/2022 19:42:55 - INFO - allennlp.common.params -   dataset_reader.token_indexers = None\n",
      "04/07/2022 19:42:55 - INFO - allennlp.common.params -   dataset_reader.domain_identifier = None\n",
      "04/07/2022 19:42:55 - INFO - allennlp.common.params -   dataset_reader.bert_model_name = bert-base-uncased\n",
      "04/07/2022 19:42:56 - INFO - allennlp.common.params -   dataset_reader.type = srl\n",
      "04/07/2022 19:42:56 - INFO - allennlp.common.params -   dataset_reader.max_instances = None\n",
      "04/07/2022 19:42:56 - INFO - allennlp.common.params -   dataset_reader.manual_distributed_sharding = False\n",
      "04/07/2022 19:42:56 - INFO - allennlp.common.params -   dataset_reader.manual_multiprocess_sharding = False\n",
      "04/07/2022 19:42:56 - INFO - allennlp.common.params -   dataset_reader.token_indexers = None\n",
      "04/07/2022 19:42:56 - INFO - allennlp.common.params -   dataset_reader.domain_identifier = None\n",
      "04/07/2022 19:42:56 - INFO - allennlp.common.params -   dataset_reader.bert_model_name = bert-base-uncased\n",
      "04/07/2022 19:42:56 - INFO - allennlp.common.params -   type = from_instances\n",
      "04/07/2022 19:42:56 - INFO - allennlp.data.vocabulary -   Loading token dictionary from /tmp/tmpq7hh7fh2/vocabulary.\n",
      "04/07/2022 19:42:56 - INFO - allennlp.common.params -   model.type = srl_bert\n",
      "04/07/2022 19:42:56 - INFO - allennlp.common.params -   model.regularizer = None\n",
      "04/07/2022 19:42:56 - INFO - allennlp.common.params -   model.bert_model = bert-base-uncased\n",
      "04/07/2022 19:42:56 - INFO - allennlp.common.params -   model.embedding_dropout = 0.1\n",
      "04/07/2022 19:42:56 - INFO - allennlp.common.params -   model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f3ea8594e10>\n",
      "04/07/2022 19:42:56 - INFO - allennlp.common.params -   model.label_smoothing = None\n",
      "04/07/2022 19:42:56 - INFO - allennlp.common.params -   model.ignore_span_metric = False\n",
      "04/07/2022 19:42:56 - INFO - allennlp.common.params -   model.srl_eval_path = /home/gxu21/env/lib/python3.7/site-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -   Initializing parameters\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -   Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.embeddings.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.embeddings.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.embeddings.position_embeddings.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.embeddings.token_type_embeddings.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.embeddings.word_embeddings.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.key.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.key.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.query.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.query.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.value.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.attention.self.value.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.intermediate.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.intermediate.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.0.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.key.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.key.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.query.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.query.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.value.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.attention.self.value.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.intermediate.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.intermediate.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.1.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.output.dense.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.key.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.key.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.query.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.query.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.value.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.attention.self.value.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.intermediate.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.intermediate.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.10.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.key.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.key.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.query.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.query.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.value.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.attention.self.value.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.intermediate.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.intermediate.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.11.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.key.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.key.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.query.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.query.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.value.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.attention.self.value.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.intermediate.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.intermediate.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.2.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.key.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.key.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.query.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.query.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.value.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.attention.self.value.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.intermediate.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.intermediate.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.3.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.key.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.key.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.query.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.query.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.value.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.attention.self.value.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.intermediate.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.4.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.key.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.key.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.query.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.query.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.value.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.attention.self.value.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.intermediate.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.intermediate.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.5.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.key.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.key.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.query.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.query.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.value.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.attention.self.value.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.intermediate.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.intermediate.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.6.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.key.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.key.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.query.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.query.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.value.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.attention.self.value.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.intermediate.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.intermediate.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.7.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.key.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.key.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.query.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.query.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.value.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.attention.self.value.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.intermediate.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.intermediate.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.8.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.output.dense.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.key.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.key.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.query.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.query.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.value.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.attention.self.value.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.intermediate.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.intermediate.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.output.LayerNorm.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.output.LayerNorm.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.output.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.encoder.layer.9.output.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.pooler.dense.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      bert_model.pooler.dense.weight\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      tag_projection_layer.bias\n",
      "04/07/2022 19:42:58 - INFO - allennlp.nn.initializers -      tag_projection_layer.weight\n",
      "04/07/2022 19:42:59 - INFO - allennlp.models.archival -   removing temporary unarchived model dir at /tmp/tmpq7hh7fh2\n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "\n",
    "\n",
    "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\", cuda_device=0)\n",
    "result = predictor.predict(\n",
    "    sentence=sentences[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e7aaf96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to check that the tokenization by allennlp has the same token length as booknlp\n",
    "import csv\n",
    "with open('allen_srl_event.csv', 'w') as f:\n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"trigger\", \"v_s\",\"v_e\", \"arg0\", \"a0_s\", \"a0_e\", \"arg1\", \"a1_s\", \"a1_e\", \"arg2\", \"a2_s\", \"a2_e\"])\n",
    "    # write a row to the csv file\n",
    "#     event_line = []\n",
    "    for idx,sent in enumerate(sentences):\n",
    "#         sent = re.sub(r'\"', '`', sent)\n",
    "        result = predictor.predict(sentence=sent)\n",
    "        assert len(result[\"words\"]) == end[idx]-start[idx]+1\n",
    "        if result == None or result[\"verbs\"]==[]:\n",
    "            continue\n",
    "        # we just select the first identified verb as trigger for the sentence.\n",
    "        event = result[\"verbs\"][0]\n",
    "        trigger = event['verb']\n",
    "        des = event['description']\n",
    "\n",
    "        v_s, v_e, arg0, a0_s, a0_e, arg1, a1_s, a1_e, arg2, a2_s, a2_e = None,None,None,None,None,None,None,None,None,None,None\n",
    "\n",
    "        for i, name in enumerate(event['tags']):\n",
    "            compons = name.split('-')\n",
    "            compons = name\n",
    "            if 'B-V' in  compons:\n",
    "                v_s,v_e = i,i\n",
    "            elif 'I-V' in compons:\n",
    "                v_e = i\n",
    "                \n",
    "            elif 'B-ARG0' in compons:\n",
    "                if a0_s == None:\n",
    "                    a0_s,a0_e = i,i\n",
    "                else:\n",
    "                    a0_e=i\n",
    "            elif 'I-ARG0' in compons:\n",
    "                a0_e = i\n",
    "                \n",
    "            elif 'B-ARG1' in compons:\n",
    "                if a1_s == None:\n",
    "                    a1_s,a1_e = i,i\n",
    "                else:\n",
    "                    a1_e=i\n",
    "            elif 'I-ARG1' in compons:\n",
    "                a1_e = i\n",
    "            elif 'B-ARG2' in compons:\n",
    "                if a2_s == None:\n",
    "                    a2_s,a2_e = i,i\n",
    "                else:\n",
    "                    a2_e=i\n",
    "            elif 'I-ARG2' in compons:\n",
    "                a2_e = i\n",
    "\n",
    "        if v_s:\n",
    "            v_s += start[idx]\n",
    "            v_e += start[idx]\n",
    "        if a0_s:\n",
    "            arg0=' '.join(result['words'][a0_s:a0_e+1])\n",
    "            a0_s += start[idx]\n",
    "            a0_e += start[idx]\n",
    "        if a1_s:\n",
    "            #arg1=' '.join(result['words'][a1_s:a1_e+1])\n",
    "            a1_s += start[idx]\n",
    "            a1_e += start[idx]\n",
    "        if a2_s:\n",
    "            arg2 = ' '.join(result['words'][a2_s:a2_e+1])\n",
    "            a2_s += start[idx]\n",
    "            a2_e += start[idx]\n",
    "        \n",
    "#         if idx == 0:\n",
    "#             print(result['words'])\n",
    "#             print(event['tags'])\n",
    "#             print(' '.join(result['words'][a1_s:a1_e+1]))\n",
    "#             #arg1=' '.join(result['words'][a1_s:a1_e+1])\n",
    "#             print(arg1)\n",
    "        if a1_s:\n",
    "            writer.writerow([trigger, v_s,v_e,  arg0, a0_s, a0_e, ' '.join(words[a1_s:a1_e+1]) , a1_s, a1_e, arg2, a2_s, a2_e])\n",
    "        else:\n",
    "            writer.writerow([trigger, v_s,v_e, arg0, a0_s, a0_e, arg1, a1_s, a1_e, arg2, a2_s, a2_e])\n",
    "#         event_line.append([trigger, v_pos, arg1, a1_s, a1_e, arg2, a2_s, a2_e])\n",
    "\n",
    "#         print(event['tags'])\n",
    "    \n",
    "    \n",
    "#     if len(result[\"words\"]) == end[idx]-start[idx]+1:\n",
    "#         pass\n",
    "#     else:\n",
    "#         print(len(result[\"words\"]),end[idx]-start[idx]+1, sent)\n",
    "#         print(result[\"words\"])\n",
    "#         print(sent)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "872d8e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' text, s`There are'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.sub(r'\"', '`', ' text, s\"There are')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7a61caf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigger</th>\n",
       "      <th>v_s</th>\n",
       "      <th>v_e</th>\n",
       "      <th>arg0</th>\n",
       "      <th>a0_s</th>\n",
       "      <th>a0_e</th>\n",
       "      <th>arg1</th>\n",
       "      <th>a1_s</th>\n",
       "      <th>a1_e</th>\n",
       "      <th>arg2</th>\n",
       "      <th>a2_s</th>\n",
       "      <th>a2_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>were</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>five - and - twenty tin soldiers , who were all brothers , for they had been made out of the same old tin spoon</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shouldered</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>arms</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heard</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>they</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uttered</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>by a little boy , who clapped his hands with delight when the lid of the box , in which they lay , was taken off</td>\n",
       "      <td>72.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>were</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>looked</td>\n",
       "      <td>1938</td>\n",
       "      <td>1938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>at the little lady</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>felt</td>\n",
       "      <td>1951</td>\n",
       "      <td>1951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>himself melting away</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>flew</td>\n",
       "      <td>1975</td>\n",
       "      <td>1975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the door of the room</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>melted</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>remained</td>\n",
       "      <td>2058</td>\n",
       "      <td>2058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nothing</td>\n",
       "      <td>2057.0</td>\n",
       "      <td>2057.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       trigger   v_s   v_e  \\\n",
       "0         were     4     4   \n",
       "1   shouldered    33    33   \n",
       "2        heard    59    59   \n",
       "3      uttered     0     0   \n",
       "4         were   100   100   \n",
       "..         ...   ...   ...   \n",
       "82      looked  1938  1938   \n",
       "83        felt  1951  1951   \n",
       "84        flew  1975  1975   \n",
       "85      melted  2017  2017   \n",
       "86    remained  2058  2058   \n",
       "\n",
       "                                                                                                                arg0  \\\n",
       "0                                                                                                                NaN   \n",
       "1                                                                                                                NaN   \n",
       "2                                                                                                               they   \n",
       "3   by a little boy , who clapped his hands with delight when the lid of the box , in which they lay , was taken off   \n",
       "4                                                                                                                NaN   \n",
       "..                                                                                                               ...   \n",
       "82                                                                                                               NaN   \n",
       "83                                                                                                               NaN   \n",
       "84                                                                                                               NaN   \n",
       "85                                                                                                               NaN   \n",
       "86                                                                                                               NaN   \n",
       "\n",
       "    a0_s  a0_e                  arg1    a1_s    a1_e  \\\n",
       "0    NaN   NaN                   NaN     0.0     3.0   \n",
       "1    0.0   0.0                  arms    34.0    34.0   \n",
       "2   57.0  57.0                   NaN     0.0     5.0   \n",
       "3   72.0  97.0                   NaN     NaN     NaN   \n",
       "4    NaN   NaN                   NaN     NaN     NaN   \n",
       "..   ...   ...                   ...     ...     ...   \n",
       "82   0.0   0.0    at the little lady  1939.0  1942.0   \n",
       "83   0.0   0.0  himself melting away  1952.0  1954.0   \n",
       "84   NaN   NaN  the door of the room  1970.0  1974.0   \n",
       "85   NaN   NaN                   NaN     0.0     2.0   \n",
       "86   NaN   NaN               nothing  2057.0  2057.0   \n",
       "\n",
       "                                                                                                               arg2  \\\n",
       "0   five - and - twenty tin soldiers , who were all brothers , for they had been made out of the same old tin spoon   \n",
       "1                                                                                                               NaN   \n",
       "2                                                                                                               NaN   \n",
       "3                                                                                                               NaN   \n",
       "4                                                                                                               NaN   \n",
       "..                                                                                                              ...   \n",
       "82                                                                                                              NaN   \n",
       "83                                                                                                              NaN   \n",
       "84                                                                                                              NaN   \n",
       "85                                                                                                              NaN   \n",
       "86                                                                                                              NaN   \n",
       "\n",
       "    a2_s  a2_e  \n",
       "0    6.0  30.0  \n",
       "1    NaN   NaN  \n",
       "2    NaN   NaN  \n",
       "3    NaN   NaN  \n",
       "4    NaN   NaN  \n",
       "..   ...   ...  \n",
       "82   NaN   NaN  \n",
       "83   NaN   NaN  \n",
       "84   NaN   NaN  \n",
       "85   NaN   NaN  \n",
       "86   NaN   NaN  \n",
       "\n",
       "[87 rows x 12 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('allen_srl_event.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38885949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0a1850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da2d8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496aa6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2690272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85325715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5dbd8651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'ARGM', 'DIS']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'B-ARGM-DIS'.split('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1f53dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('remained', 6, 'nothing', 5, 5, None, None, None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigger = result['verbs'][0]['verb']\n",
    "v_pos, arg1, a1_s, a1_e, arg2, a2_s, a2_e = None,None,None,None,None,None,None\n",
    "\n",
    "for i, name in enumerate(result['verbs'][0]['tags']):\n",
    "    compons = name.split('-')\n",
    "    compons = name\n",
    "    if 'B-V' in  compons:\n",
    "        v_pos = i\n",
    "    elif 'B-ARG1' in compons:\n",
    "        if a1_s == None:\n",
    "            a1_s,a1_e = i,i\n",
    "        else:\n",
    "            a1_e=i\n",
    "    elif 'B-ARG2' in compons:\n",
    "        if a2_s == None:\n",
    "            a2_s,a2_e = i,i\n",
    "        else:\n",
    "            a2_e=i\n",
    "if a1_s:\n",
    "    arg1 = ' '.join(result['words'][a1_s:a1_e+1])\n",
    "if a2_s:\n",
    "    arg2 = result['words'][a2_s:a2_e+1]\n",
    "trigger, v_pos, arg1, a1_s, a1_e, arg2, a2_s, a2_e \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e1f1b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['But',\n",
       " 'of',\n",
       " 'the',\n",
       " 'little',\n",
       " 'dancer',\n",
       " 'nothing',\n",
       " 'remained',\n",
       " 'but',\n",
       " 'the',\n",
       " 'tinsel',\n",
       " 'rose',\n",
       " ',',\n",
       " 'which',\n",
       " 'was',\n",
       " 'burnt',\n",
       " 'black',\n",
       " 'as',\n",
       " 'a',\n",
       " 'cinder',\n",
       " '.',\n",
       " \"'\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "851a0d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ARGM-DIS',\n",
       " 'B-ARG3',\n",
       " 'I-ARG3',\n",
       " 'I-ARG3',\n",
       " 'I-ARG3',\n",
       " 'B-ARG1',\n",
       " 'B-V',\n",
       " 'B-C-ARG1',\n",
       " 'I-C-ARG1',\n",
       " 'I-C-ARG1',\n",
       " 'I-C-ARG1',\n",
       " 'I-C-ARG1',\n",
       " 'I-C-ARG1',\n",
       " 'I-C-ARG1',\n",
       " 'I-C-ARG1',\n",
       " 'I-C-ARG1',\n",
       " 'I-C-ARG1',\n",
       " 'I-C-ARG1',\n",
       " 'I-C-ARG1',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['verbs'][0]['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f7d400a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first thing in the world they ever heard were the words , \\t \\t'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5c2d438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['verbs', 'words'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cda6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e45e116b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['verb', 'description', 'tags'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"verbs\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab753c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"/home/gxu21/ECONET/code/data_process/FairytaleQA_Dataset/split_by_origin/andersen-fairybook/brave-tin-soldier-story/brave-tin-soldier-story.tokens\"\n",
    "df = pd.read_csv(path, sep=\"\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99fea66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[-590:-560]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ee8de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#words is a list of all extracted tokens from the .token file\n",
    "words = list(df[\"word\"])\n",
    "len(words)\n",
    "words_dict = dict()\n",
    "for i,w in enumerate(words):\n",
    "    words_dict[i] = w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abcb185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the words into a new df of sentences, which includes their start and end token_pos\n",
    "sentences = []\n",
    "start = []\n",
    "end = []\n",
    "sent = None\n",
    "for i,w in enumerate(words):\n",
    "    if sent == None:\n",
    "        if w == \"\\t\":\n",
    "            sent+= \"'\"\n",
    "        else:\n",
    "            sent = w\n",
    "        start_id =i\n",
    "    else:\n",
    "        if w == \"\\t\":\n",
    "            sent+= \" '\"\n",
    "        else:\n",
    "            sent+= \" \"+ w\n",
    "    if (w == \".\" or w == \"\\t\") and (i+1>=len(words) or words[i+1]!='\\t'):\n",
    "        end_id = i\n",
    "        sentences.append(sent)\n",
    "        start.append(start_id)\n",
    "        end.append(end_id)\n",
    "        sent = None\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c15ff8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df = pd.DataFrame({\"sentence\":sentences})\n",
    "sent_df[\"start_id\"] = start\n",
    "sent_df[\"end_id\"] = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77452731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>start_id</th>\n",
       "      <th>end_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>section , text 1,\"There were once five - and - twenty tin soldiers , who were all brothers , for they had been made out of the same old tin spoon .</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They shouldered arms and looked straight before them , and wore a splendid uniform , red and blue .</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The first thing in the world they ever heard were the words , ' '</td>\n",
       "      <td>51</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tin soldiers ! ' '</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uttered by a little boy , who clapped his hands with delight when the lid of the box , in which they lay , was taken off .</td>\n",
       "      <td>71</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>They were given him for a birthday present , and he stood at the table to set them up .</td>\n",
       "      <td>99</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The soldiers were all exactly alike , excepting one , who had only one leg ; he had been left to the last , and then there was not enough of the melted tin to finish him , so they made him to stand firmly on one leg , and this caused him to be very remarkable . '</td>\n",
       "      <td>119</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2,\"The table on which the tin soldiers stood , was covered with other playthings , but the most attractive to the eye was a pretty little paper castle .</td>\n",
       "      <td>178</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Through the small windows the rooms could be seen .</td>\n",
       "      <td>207</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In front of the castle a number of little trees surrounded a piece of looking - glass , which was intended to represent a transparent lake .</td>\n",
       "      <td>217</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Swans , made of wax , swam on the lake , and were reflected in it .</td>\n",
       "      <td>244</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>All this was very pretty , but the prettiest of all was a tiny little lady , who stood at the open door of the castle ; she , also , was made of paper , and she wore a dress of clear muslin , with a narrow blue ribbon over her shoulders just like a scarf .</td>\n",
       "      <td>261</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>In front of these was fixed a glittering tinsel rose , as large as her whole face . '</td>\n",
       "      <td>319</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3,\"The little lady was a dancer , and she stretched out both her arms , and raised one of her legs so high , that the tin soldier could not see it at all , and he thought that she , like himself , had only one leg . ' '</td>\n",
       "      <td>338</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>That is the wife for me , ' '</td>\n",
       "      <td>389</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>he thought ; ' '</td>\n",
       "      <td>398</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>but she is too grand , and lives in a castle , while I have only a box to live in , five - and - twenty of us altogether , that is no place for her .</td>\n",
       "      <td>403</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Still I must try and make her acquaintance . ' '</td>\n",
       "      <td>441</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Then he laid himself at full length on the table behind a snuff - box that stood upon it , so that he could peep at the little delicate lady , who continued to stand on one leg without losing her balance . '</td>\n",
       "      <td>452</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4,\"When evening came , the other tin soldiers were all placed in the box , and the people of the house went to bed .</td>\n",
       "      <td>496</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Then the playthings began to have their own games together , to pay visits , to have sham fights , and to give balls .</td>\n",
       "      <td>521</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The tin soldiers rattled in their box ; they wanted to get out and join the amusements , but they could not open the lid .</td>\n",
       "      <td>546</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The nut - crackers played at leap - frog , and the pencil jumped about the table .</td>\n",
       "      <td>572</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>There was such a noise that the canary woke up and began to talk , and in poetry too .</td>\n",
       "      <td>590</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Only the tin soldier and the dancer remained in their places .</td>\n",
       "      <td>610</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>She stood on tiptoe , with her legs stretched out , as firmly as he did on his one leg .</td>\n",
       "      <td>622</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>He never took his eyes from her for even a moment .</td>\n",
       "      <td>643</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The clock struck twelve , and , with a bounce , up sprang the lid of the snuff - box ; but , instead of snuff , there jumped up a little black goblin ; for the snuff - box was a toy puzzle . '</td>\n",
       "      <td>655</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5,\"\"\"Tin soldier , ' '</td>\n",
       "      <td>701</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>said the goblin , ' '</td>\n",
       "      <td>706</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                   sentence  \\\n",
       "0                                                                                                                       section , text 1,\"There were once five - and - twenty tin soldiers , who were all brothers , for they had been made out of the same old tin spoon .   \n",
       "1                                                                                                                                                                       They shouldered arms and looked straight before them , and wore a splendid uniform , red and blue .   \n",
       "2                                                                                                                                                                                                         The first thing in the world they ever heard were the words , ' '   \n",
       "3                                                                                                                                                                                                                                                        Tin soldiers ! ' '   \n",
       "4                                                                                                                                                uttered by a little boy , who clapped his hands with delight when the lid of the box , in which they lay , was taken off .   \n",
       "5                                                                                                                                                                                   They were given him for a birthday present , and he stood at the table to set them up .   \n",
       "6   The soldiers were all exactly alike , excepting one , who had only one leg ; he had been left to the last , and then there was not enough of the melted tin to finish him , so they made him to stand firmly on one leg , and this caused him to be very remarkable . '   \n",
       "7                                                                                                                  2,\"The table on which the tin soldiers stood , was covered with other playthings , but the most attractive to the eye was a pretty little paper castle .   \n",
       "8                                                                                                                                                                                                                       Through the small windows the rooms could be seen .   \n",
       "9                                                                                                                              In front of the castle a number of little trees surrounded a piece of looking - glass , which was intended to represent a transparent lake .   \n",
       "10                                                                                                                                                                                                      Swans , made of wax , swam on the lake , and were reflected in it .   \n",
       "11         All this was very pretty , but the prettiest of all was a tiny little lady , who stood at the open door of the castle ; she , also , was made of paper , and she wore a dress of clear muslin , with a narrow blue ribbon over her shoulders just like a scarf .   \n",
       "12                                                                                                                                                                                    In front of these was fixed a glittering tinsel rose , as large as her whole face . '   \n",
       "13                                              3,\"The little lady was a dancer , and she stretched out both her arms , and raised one of her legs so high , that the tin soldier could not see it at all , and he thought that she , like himself , had only one leg . ' '   \n",
       "14                                                                                                                                                                                                                                            That is the wife for me , ' '   \n",
       "15                                                                                                                                                                                                                                                         he thought ; ' '   \n",
       "16                                                                                                                    but she is too grand , and lives in a castle , while I have only a box to live in , five - and - twenty of us altogether , that is no place for her .   \n",
       "17                                                                                                                                                                                                                         Still I must try and make her acquaintance . ' '   \n",
       "18                                                          Then he laid himself at full length on the table behind a snuff - box that stood upon it , so that he could peep at the little delicate lady , who continued to stand on one leg without losing her balance . '   \n",
       "19                                                                                                                                                     4,\"When evening came , the other tin soldiers were all placed in the box , and the people of the house went to bed .   \n",
       "20                                                                                                                                                   Then the playthings began to have their own games together , to pay visits , to have sham fights , and to give balls .   \n",
       "21                                                                                                                                               The tin soldiers rattled in their box ; they wanted to get out and join the amusements , but they could not open the lid .   \n",
       "22                                                                                                                                                                                       The nut - crackers played at leap - frog , and the pencil jumped about the table .   \n",
       "23                                                                                                                                                                                   There was such a noise that the canary woke up and began to talk , and in poetry too .   \n",
       "24                                                                                                                                                                                                           Only the tin soldier and the dancer remained in their places .   \n",
       "25                                                                                                                                                                                 She stood on tiptoe , with her legs stretched out , as firmly as he did on his one leg .   \n",
       "26                                                                                                                                                                                                                      He never took his eyes from her for even a moment .   \n",
       "27                                                                         The clock struck twelve , and , with a bounce , up sprang the lid of the snuff - box ; but , instead of snuff , there jumped up a little black goblin ; for the snuff - box was a toy puzzle . '   \n",
       "28                                                                                                                                                                                                                                                   5,\"\"\"Tin soldier , ' '   \n",
       "29                                                                                                                                                                                                                                                    said the goblin , ' '   \n",
       "\n",
       "    start_id  end_id  \n",
       "0          0      31  \n",
       "1         32      50  \n",
       "2         51      65  \n",
       "3         66      70  \n",
       "4         71      98  \n",
       "5         99     118  \n",
       "6        119     177  \n",
       "7        178     206  \n",
       "8        207     216  \n",
       "9        217     243  \n",
       "10       244     260  \n",
       "11       261     318  \n",
       "12       319     337  \n",
       "13       338     388  \n",
       "14       389     397  \n",
       "15       398     402  \n",
       "16       403     440  \n",
       "17       441     451  \n",
       "18       452     495  \n",
       "19       496     520  \n",
       "20       521     545  \n",
       "21       546     571  \n",
       "22       572     589  \n",
       "23       590     609  \n",
       "24       610     621  \n",
       "25       622     642  \n",
       "26       643     654  \n",
       "27       655     700  \n",
       "28       701     705  \n",
       "29       706     711  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)  # or 199\n",
    "sent_df.iloc[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a313fef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
