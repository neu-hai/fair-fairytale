{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10282ce7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The story takes place in Baghdad during the Abbasid era. ',\n",
       " 'Ali Baba and his elder brother Cassim are the sons of a merchant. ',\n",
       " \"After the death of their father, the greedy Cassim marries a wealthy woman and becomes well-to-do, building on their father's business - but Ali Baba marries a poor woman and settles into the trade of a woodcutter. \",\n",
       " 'One day Ali Baba is at work collecting and cutting firewood in the forest, and he happens to overhear a group of forty thieves visiting their treasure store. ',\n",
       " 'The treasure is in a cave, the mouth of which is sealed by magic. ',\n",
       " 'It opens on the words \"Open, Simsim\", and seals itself on the words \"Close, Simsim\". ',\n",
       " 'When the thieves are gone, Ali Baba enters the cave himself, and takes some of the treasure home. ',\n",
       " \"Ali Baba borrows his sister-in-law's scales to weigh this new wealth of gold coins. \",\n",
       " 'Unbeknownst to Ali, she puts a blob of wax in the scales to find out what Ali is using them for, as she is curious to know what kind of grain her impoverished brother-in-law needs to measure. ',\n",
       " \"To her shock, she finds a gold coin sticking to the scales and tells her husband, Ali Baba's rich and greedy brother, Cassim. \",\n",
       " 'Under pressure from his brother, Ali Baba is forced to reveal the secret of the cave. ',\n",
       " 'Cassim goes to the cave and enters with the magic words, but in his greed and excitement over the treasures forgets the magic words to get back out again. ',\n",
       " 'The thieves find him there, and kill him. ',\n",
       " 'When his brother does not come back, Ali Baba goes to the cave to look for him, and finds the body, quartered and with each piece displayed just inside the entrance of the cave to discourage any similar attempts in the future. ',\n",
       " \"Ali Baba brings the body home, where he entrusts Morgiana, a clever slave-girl in Cassim's household, with the task of making others believe that Cassim has died a natural death. \",\n",
       " \"First, Morgiana purchases medicines from an apothecary, telling him that Cassim is gravely ill. Then, she finds an old tailor known as Baba Mustafa whom she pays, blindfolds, and leads to Cassim's house. \",\n",
       " \"There, overnight, the tailor stitches the pieces of Cassims' body back together, so that no one will be suspicious. \",\n",
       " 'Ali and his family are able to give Cassim a proper burial without anyone asking awkward questions. ',\n",
       " 'The thieves, finding the body gone, realize that yet another person must know their secret, and set out to track him down. ',\n",
       " \"One of the thieves goes down to the town and comes across Baba Mustafa, who mentions that he has just sewn a dead man's body back together. \",\n",
       " \"Realizing that the dead man must have been the thieves' victim, the thief asks Baba Mustafa to lead the way to the house where the deed was performed. \",\n",
       " 'The tailor is blindfolded again, and in this state he is able to retrace his steps and find the house. ',\n",
       " 'The thief marks the door with a symbol. ',\n",
       " 'The plan is for the other thieves to come back that night and kill everyone in the house. ',\n",
       " 'However, the thief has been seen by Morgiana and she, loyal to her master, foils his plan by marking all the houses in the neighborhood with a similar marking. ',\n",
       " 'When the 40 thieves return that night, they cannot identify the correct house and the head thief kills the lesser thief. ',\n",
       " \"The next day, another thief revisits Baba Mustafa and tries again, only this time, a chunk is chipped out of the stone step at Ali Baba's front door. \",\n",
       " 'Again Morgiana foils the plan by making similar chips in all the other doorsteps. ',\n",
       " 'The second thief is killed for his stupidity as well. ',\n",
       " 'At last, the head thief goes and looks for himself. ',\n",
       " \"This time, he memorizes every detail he can of the exterior of Ali Baba's house. \",\n",
       " \"The chief of the thieves pretends to be an oil merchant in need of Ali Baba's hospitality, bringing with him Forty thieves hiding in oil jarsmules loaded with thirty-eight oil jars, one filled with oil, the other thirty-seven hiding the other remaining thieves. \",\n",
       " 'Once Ali Baba is asleep, the thieves plan to kill him. ',\n",
       " 'Again, Morgiana discovers and foils the plan, killing the thirty-seven thieves in their oil jars by pouring boiling oil on them. ',\n",
       " 'When their leader comes to rouse his men, he discovers that they are dead, and escapes. ',\n",
       " \"To exact revenge, after some time the thief establishes himself as a merchant, befriends Ali Baba's son (who is now in charge of the late Cassim's business), and is invited to dinner at Ali Baba's house. \",\n",
       " 'The thief is recognized by Morgiana, who performs a dance with a dagger for the diners and plunges it into the heart of the thief when he is off his guard. ',\n",
       " 'Ali Baba is at first angry with Morgiana, but when he finds out the thief tried to kill him, he gives Morgiana her freedom and marries her to his son. ',\n",
       " 'Ali Baba is then left as the only one knowing the secret of the treasure in the cave and how to access it. ',\n",
       " 'Thus, the story ends happily for everyone except the forty thieves and Cassim.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "df = pd.read_csv('ali-baba-and-forty-thieves.actions_args.csv')\n",
    "\n",
    "with open('ali-baba-and-forty-thieves.srl.json') as json_data:\n",
    "    srl = json.load(json_data)\n",
    "sentences_df = pd.read_csv('ali-baba-and-forty-thieves.sentences.csv')\n",
    "sentences = sentences_df['text'].to_list()\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f661e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_additional_arguments(df, srl, sentences):\n",
    "    adobj_start_bytes = []\n",
    "    adobj_end_bytes = []\n",
    "    offsets = []\n",
    "    for idx in range(df.shape[0]):\n",
    "        row = df.iloc[idx]\n",
    "        s_id, v_id = row['sentence_id'], row['verb_id']\n",
    "        token_start_end_bytes = get_tokens_start_end_bytes(srl[s_id]['words'], sentences[s_id])\n",
    "        sentence, verb = sentences[s_id], srl[s_id]['verbs'][v_id]\n",
    "        dobj_end = row['dobj_end_byte']\n",
    "        tags = verb['tags']\n",
    "        adobj_start_byte, adobj_end_byte = None, None\n",
    "\n",
    "        start_fixed = False\n",
    "        for i, tag in enumerate(tags):\n",
    "            # if it's a modifier argument after the verb, we add modifier argument columns\n",
    "            if check_M_arg(tag) and token_start_end_bytes[i]['start_byte'] > dobj_end:\n",
    "                if not start_fixed:\n",
    "                    adobj_start_byte, adobj_end_byte = token_start_end_bytes[i]['start_byte'], token_start_end_bytes[i][\n",
    "                        'end_byte']\n",
    "                    start_fixed = True\n",
    "                else:\n",
    "                    adobj_end_byte = token_start_end_bytes[i]['end_byte']\n",
    "\n",
    "                j = i + 1\n",
    "                while check_M_arg(tags[j]):\n",
    "                    adobj_end_byte = token_start_end_bytes[j]['end_byte']\n",
    "                    j += 1\n",
    "\n",
    "        adobj_start_bytes.append(adobj_start_byte)\n",
    "        adobj_end_bytes.append(adobj_end_byte)\n",
    "        if adobj_start_byte:\n",
    "            offsets.append(row['subj_start_byte_text'] - row['subj_start_byte'])\n",
    "        else:\n",
    "            offsets.append(None)\n",
    "\n",
    "    df['adobj_start_bytes'] = adobj_start_bytes\n",
    "    df['adobj_end_bytes'] = adobj_end_bytes\n",
    "    df['adobj_start_bytes_text'] = [adobj_start_bytes[i] + offsets[i] if offsets[i] else None for i in\n",
    "                                    range(len(offsets))]\n",
    "    df['adobj_end_bytes_text'] = [adobj_end_bytes[i] + offsets[i] if offsets[i] else None for i in range(len(offsets))]\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4958dda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>verb_id</th>\n",
       "      <th>verb</th>\n",
       "      <th>verb_start_byte</th>\n",
       "      <th>verb_end_byte</th>\n",
       "      <th>verb_start_byte_text</th>\n",
       "      <th>verb_end_byte_text</th>\n",
       "      <th>subj_coref_ids</th>\n",
       "      <th>subj_start_byte</th>\n",
       "      <th>subj_end_byte</th>\n",
       "      <th>...</th>\n",
       "      <th>dobj_start_byte</th>\n",
       "      <th>dobj_end_byte</th>\n",
       "      <th>dobj_start_byte_text</th>\n",
       "      <th>dobj_end_byte_text</th>\n",
       "      <th>supersense_category</th>\n",
       "      <th>event_label</th>\n",
       "      <th>adobj_start_bytes</th>\n",
       "      <th>adobj_end_bytes</th>\n",
       "      <th>adobj_start_bytes_text</th>\n",
       "      <th>adobj_end_bytes_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>marries</td>\n",
       "      <td>51</td>\n",
       "      <td>58</td>\n",
       "      <td>174</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>verb.social</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>becomes</td>\n",
       "      <td>79</td>\n",
       "      <td>86</td>\n",
       "      <td>202</td>\n",
       "      <td>209</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>verb.change</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>building</td>\n",
       "      <td>99</td>\n",
       "      <td>107</td>\n",
       "      <td>222</td>\n",
       "      <td>230</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>verb.consumption</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>marries</td>\n",
       "      <td>150</td>\n",
       "      <td>157</td>\n",
       "      <td>273</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>141.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>...</td>\n",
       "      <td>158.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>verb.social</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>collecting</td>\n",
       "      <td>28</td>\n",
       "      <td>38</td>\n",
       "      <td>366</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>verb.contact</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>tried</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "      <td>4571</td>\n",
       "      <td>4576</td>\n",
       "      <td>55</td>\n",
       "      <td>64.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4577.0</td>\n",
       "      <td>4588.0</td>\n",
       "      <td>verb.social</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>kill</td>\n",
       "      <td>83</td>\n",
       "      <td>87</td>\n",
       "      <td>4580</td>\n",
       "      <td>4584</td>\n",
       "      <td>55</td>\n",
       "      <td>64.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4585.0</td>\n",
       "      <td>4588.0</td>\n",
       "      <td>verb.contact</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>gives</td>\n",
       "      <td>96</td>\n",
       "      <td>101</td>\n",
       "      <td>4593</td>\n",
       "      <td>4598</td>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>102.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>4599.0</td>\n",
       "      <td>4607.0</td>\n",
       "      <td>verb.possession</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>marries</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>4624</td>\n",
       "      <td>4631</td>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4632.0</td>\n",
       "      <td>4635.0</td>\n",
       "      <td>verb.social</td>\n",
       "      <td>1</td>\n",
       "      <td>139.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>4636.0</td>\n",
       "      <td>4646.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>left</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>4665</td>\n",
       "      <td>4669</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>4670.0</td>\n",
       "      <td>4753.0</td>\n",
       "      <td>verb.cognition</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence_id  verb_id        verb  verb_start_byte  verb_end_byte  \\\n",
       "0             2        0     marries               51             58   \n",
       "1             2        1     becomes               79             86   \n",
       "2             2        2    building               99            107   \n",
       "3             2        3     marries              150            157   \n",
       "4             3        1  collecting               28             38   \n",
       "..          ...      ...         ...              ...            ...   \n",
       "78           37        2       tried               74             79   \n",
       "79           37        3        kill               83             87   \n",
       "80           37        4       gives               96            101   \n",
       "81           37        5     marries              127            134   \n",
       "82           38        1        left               17             21   \n",
       "\n",
       "    verb_start_byte_text  verb_end_byte_text subj_coref_ids  subj_start_byte  \\\n",
       "0                    174                 181              2             33.0   \n",
       "1                    202                 209              2             33.0   \n",
       "2                    222                 230              2             33.0   \n",
       "3                    273                 280              1            141.0   \n",
       "4                    366                 376              1              8.0   \n",
       "..                   ...                 ...            ...              ...   \n",
       "78                  4571                4576             55             64.0   \n",
       "79                  4580                4584             55             64.0   \n",
       "80                  4593                4598              1             93.0   \n",
       "81                  4624                4631              1             93.0   \n",
       "82                  4665                4669              1              0.0   \n",
       "\n",
       "    subj_end_byte  ...  dobj_start_byte  dobj_end_byte dobj_start_byte_text  \\\n",
       "0            50.0  ...             59.0           74.0                182.0   \n",
       "1            50.0  ...             87.0           97.0                210.0   \n",
       "2            50.0  ...            108.0          134.0                231.0   \n",
       "3           149.0  ...            158.0          170.0                281.0   \n",
       "4            16.0  ...             51.0           59.0                389.0   \n",
       "..            ...  ...              ...            ...                  ...   \n",
       "78           73.0  ...             80.0           91.0               4577.0   \n",
       "79           73.0  ...             88.0           91.0               4585.0   \n",
       "80           95.0  ...            102.0          110.0               4599.0   \n",
       "81           95.0  ...            135.0          138.0               4632.0   \n",
       "82            8.0  ...             22.0          105.0               4670.0   \n",
       "\n",
       "    dobj_end_byte_text  supersense_category  event_label  adobj_start_bytes  \\\n",
       "0                197.0          verb.social            1                NaN   \n",
       "1                220.0          verb.change            1                NaN   \n",
       "2                257.0     verb.consumption            1                NaN   \n",
       "3                293.0          verb.social            1                NaN   \n",
       "4                397.0         verb.contact            1               60.0   \n",
       "..                 ...                  ...          ...                ...   \n",
       "78              4588.0          verb.social            1                NaN   \n",
       "79              4588.0         verb.contact            1                NaN   \n",
       "80              4607.0      verb.possession            1                NaN   \n",
       "81              4635.0          verb.social            1              139.0   \n",
       "82              4753.0       verb.cognition            1                NaN   \n",
       "\n",
       "   adobj_end_bytes  adobj_start_bytes_text  adobj_end_bytes_text  \n",
       "0              NaN                     NaN                   NaN  \n",
       "1              NaN                     NaN                   NaN  \n",
       "2              NaN                     NaN                   NaN  \n",
       "3              NaN                     NaN                   NaN  \n",
       "4             73.0                   398.0                 411.0  \n",
       "..             ...                     ...                   ...  \n",
       "78             NaN                     NaN                   NaN  \n",
       "79             NaN                     NaN                   NaN  \n",
       "80             NaN                     NaN                   NaN  \n",
       "81           149.0                  4636.0                4646.0  \n",
       "82             NaN                     NaN                   NaN  \n",
       "\n",
       "[83 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_additional_arguments(df, srl, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985da2cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adobj_start_bytes = []\n",
    "adobj_end_bytes = []\n",
    "offsets = []\n",
    "for idx in range(df.shape[0]):\n",
    "    row = df.iloc[idx]\n",
    "    s_id,v_id = row['sentence_id'], row['verb_id']\n",
    "    token_start_end_bytes = get_tokens_start_end_bytes(srl[s_id]['words'], sentences[s_id])\n",
    "    sentence, verb = sentences[s_id], srl[s_id]['verbs'][v_id]\n",
    "    dobj_end = row['dobj_end_byte']\n",
    "    tags = verb['tags']\n",
    "    adobj_start_byte, adobj_end_byte = None,None\n",
    "    \n",
    "    start_fixed = False\n",
    "    for i, tag in enumerate(tags):        \n",
    "        #if it's a modifier argument after the verb, we add modifier argument columns\n",
    "        if check_M_arg(tag) and token_start_end_bytes[i]['start_byte']>dobj_end:\n",
    "            if not start_fixed:\n",
    "                adobj_start_byte, adobj_end_byte = token_start_end_bytes[i]['start_byte'], token_start_end_bytes[i]['end_byte']\n",
    "                start_fixed = True\n",
    "            else:\n",
    "                adobj_end_byte = token_start_end_bytes[i]['end_byte']\n",
    "\n",
    "            j=i+1\n",
    "            while check_M_arg(tags[j]):\n",
    "                adobj_end_byte = token_start_end_bytes[j]['end_byte']\n",
    "                j+=1\n",
    "                \n",
    "    adobj_start_bytes.append(adobj_start_byte)\n",
    "    adobj_end_bytes.append(adobj_end_byte)\n",
    "    if adobj_start_byte:\n",
    "        offsets.append(row['subj_start_byte_text']-row['subj_start_byte'])\n",
    "    else:\n",
    "        offsets.append(None)\n",
    "            \n",
    "                \n",
    "df['adobj_start_bytes'] = adobj_start_bytes\n",
    "df['adobj_end_bytes'] = adobj_end_bytes\n",
    "df['adobj_start_bytes_text'] = [adobj_start_bytes[i]+offsets[i] if offsets[i] else None for i in range(len(offsets))]\n",
    "df['adobj_end_bytes_text'] = [adobj_end_bytes[i]+offsets[i] if offsets[i] else None for i in range(len(offsets))]\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "#             arg_token_start_end_bytes.append((tokens_start_end_bytes[i]['start_byte'], tokens_start_end_bytes[i]['end_byte']))\n",
    "#             tokens.append(words[i])\n",
    "#             j = i + 1\n",
    "#             while (j < len(verb['tags'])) and check_I_arg(verb['tags'][j]):\n",
    "#                 tokens.append(words[j])\n",
    "#                 arg_token_start_end_bytes.append((tokens_start_end_bytes[j]['start_byte'], tokens_start_end_bytes[j]['end_byte']))\n",
    "#                 j += 1\n",
    "#             # Get start and end bytes of tokens\n",
    "#             start_byte = tokens_start_end_bytes[i]['start_byte']\n",
    "#             end_byte = tokens_start_end_bytes[j-1]['end_byte']\n",
    "    \n",
    "#     print(token_start_end_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce601821",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71ac1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# SRL Argument Functions\n",
    "def check_B_arg(text: str):\n",
    "    return re.search(r'B-ARG\\d+', text) is not None\n",
    "\n",
    "def check_I_arg(text: str):\n",
    "    return re.search(r'I-ARG\\d+', text) is not None\n",
    "\n",
    "def check_arg(text: str):\n",
    "    return re.search(r'ARG\\d+', text) is not None\n",
    "\n",
    "def check_verb(text: str):\n",
    "    return re.search(r'\\w-V', text) is not None\n",
    "\n",
    "def check_M_arg(text: str):\n",
    "    return re.search(r'\\D-ARGM\\D', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3605e469",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_B_arg(sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b02f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edfe5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(r'\\D-ARGM\\D', srl[0]['verbs'][0]['tags'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a4a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl[0]['verbs'][0]['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0badefad",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5512017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tokens_start_end_bytes(tokens, sentence):\n",
    "    token_start_end_bytes_sentence = []\n",
    "\n",
    "    s = 0\n",
    "    for i, token in enumerate(tokens):\n",
    "        token_start_end_bytes = {}\n",
    "\n",
    "        token_start_end_bytes['token'] = token\n",
    "        token_start_end_bytes['i'] = i\n",
    "\n",
    "        start_byte = s\n",
    "        end_byte = s + len(token)\n",
    "\n",
    "        if sentence[start_byte] == ' ':\n",
    "            start_byte += 1\n",
    "            end_byte += 1\n",
    "\n",
    "        #print(start_byte, end_byte)\n",
    "        #print(sentence[start_byte])\n",
    "        #print(sentence[end_byte])\n",
    "        #print(\"mapping :\", token, sentence[start_byte:end_byte])\n",
    "        #print(\"\\n\")\n",
    "\n",
    "        if token != sentence[start_byte:end_byte]:\n",
    "            print('Incorrect mapping of token to sentence bytes.')\n",
    "            print(i, token, sentence[start_byte:end_byte])\n",
    "\n",
    "        token_start_end_bytes['start_byte'] = start_byte\n",
    "        token_start_end_bytes['end_byte'] = end_byte\n",
    "\n",
    "        token_start_end_bytes_sentence.append(token_start_end_bytes)\n",
    "\n",
    "        s = end_byte\n",
    "\n",
    "    return token_start_end_bytes_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9775ab75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1199747",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66641f29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
